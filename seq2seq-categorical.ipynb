{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Based on the followings:\n",
    "* http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "* http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
    "* https://machinelearningmastery.com/configure-encoder-decoder-model-neural-machine-translation/\n",
    "* https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence-prediction-keras/\n",
    "* https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
    "* https://github.com/farizrahman4u/seq2seq\n",
    "* https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "\n",
    "## TODO\n",
    "* ~~look into categorical representation~~\n",
    "* ~~look into the number of missing words over the total~~\n",
    "* ~~look into different models (attention, hierachical, etc.)~~\n",
    "* compute BLEU on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from string import punctuation\n",
    "from itertools import islice\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer, Input, LSTM, GRU, Dense, Masking, Embedding, Activation\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, Callback\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data'\n",
    "OUTPUT_PATH = 'output'\n",
    "punct = set(punctuation)\n",
    "file_list = sorted(glob.glob('data/parsed/*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = KeyedVectors.load_word2vec_format(os.path.join(DATA_PATH, 'GoogleNews-vectors-negative300.bin.gz'), binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-load params\n",
    "with open(os.path.join(DATA_PATH, 'data_20k.pkl'), 'rb') as data_file, open(os.path.join(DATA_PATH, 'params_20k.pkl'), 'rb') as params_file:\n",
    "    data = pkl.load(data_file)\n",
    "    params = pkl.load(params_file)\n",
    "    tokenizer = params['tokenizer']\n",
    "    index_word = params['index_word']\n",
    "    word2embeddings = params['w2e']\n",
    "    embedding_matrix = params['W']\n",
    "    missing_words = params['missing_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300#w2v.vector_size\n",
    "eos_token = 'EOS'\n",
    "unk_token = 'UNK'\n",
    "eos_vector = np.ones((embedding_dim))\n",
    "unk_vector = np.zeros((embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(repl='', string=text, pattern='^> ') # remove starting caret, if any\n",
    "    text = re.sub(repl='\\g<1> \\g<2>', string=text, pattern='(\\w+)-(\\w+)') # compound words    \n",
    "    text = re.sub(repl=' ', string=text, pattern='-{2,}|\\s{2,}|[%s\\t\\n/]' % (''.join(punctuation)))\n",
    "#     text = re.sub(repl=' digits ', string=text, pattern='^\\d+$| \\d+| \\d+ ') # replace digits with a standard 'digits' word\n",
    "    return text\n",
    "\n",
    "def read_corpus(file_list):\n",
    "    corpus = []\n",
    "    for file in file_list:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            print('read_corpus: processing [{}]'.format(file))\n",
    "            corpus.append(f.read())\n",
    "            \n",
    "    return corpus\n",
    "            \n",
    "def build_vocabulary(corpus, num_words, oov_token):\n",
    "    tokenizer = Tokenizer(num_words=num_words+1, oov_token=oov_token) # +1 for the oov token\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    \n",
    "    # Fix keras' nasty behaviour. See https://github.com/keras-team/keras/issues/8092\n",
    "    # Only include words found in w2v\n",
    "    tokenizer.word_index = {w:i for  w,i in tokenizer.word_index.items() \n",
    "                                if   i <= num_words} # <= because tokenizer is 1 indexed (this will leave out UNK)\n",
    "    tokenizer.num_words = num_words + 2  # UNK + EOS\n",
    "    tokenizer.word_index[oov_token] = len(tokenizer.word_index) + 1\n",
    "    tokenizer.word_index[eos_token] = len(tokenizer.word_index) + 1\n",
    "    index_word = [None for i in range(len(tokenizer.word_index) + 1)]  # index is 1-based\n",
    "    for w,i in tokenizer.word_index.items():\n",
    "        index_word[i] = w\n",
    "    \n",
    "    return tokenizer, index_word\n",
    "\n",
    "def prepare_data(corpus, tokenizer):\n",
    "    # Still go through the files line by line, as we want to predict the next scene, \n",
    "    # not just the next sentence\n",
    "    data = []\n",
    "    for i, doc in enumerate(corpus):\n",
    "        doc_data = []\n",
    "        print('prepare_data: processing [{}]'.format(file_list[i]))\n",
    "        \n",
    "        for j, line in enumerate(doc.split('\\n')):\n",
    "            if len(line) == 0:\n",
    "                print('Line {} is empty. Replacing with \"empty line\".'.format(j+1))\n",
    "                line = 'empty line'\n",
    "\n",
    "            doc_data.append(tokenizer.texts_to_sequences([line])[0])\n",
    "\n",
    "        if len(doc_data) == 0:\n",
    "            print('File {} has no data'.format(file_list[i]))\n",
    "        else:\n",
    "            data.append(doc_data)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def get_embeddings(word_index, w2v, unk_vector):\n",
    "    embedding_matrix=np.zeros(shape=(len(word_index)+2, w2v.vector_size))  # +2 as keras' tokenizer is 1-based\n",
    "    missing_words = []\n",
    "    for word,i in word_index.items():\n",
    "        if word not in w2v:\n",
    "            # Try to capitalize it\n",
    "            if word.capitalize() not in w2v:\n",
    "                missing_words.append(word)\n",
    "                embedding_matrix[i] = unk_vector\n",
    "            else:\n",
    "                embedding_matrix[i] = w2v[word.capitalize()]\n",
    "        else:\n",
    "            embedding_matrix[i] = w2v[word]\n",
    "    \n",
    "    # add EOS token\n",
    "    embedding_matrix[-1] = eos_vector # keras' index the vocab starting from 1\n",
    "    embedding_matrix[-2] = unk_vector\n",
    "    return embedding_matrix, missing_words\n",
    "\n",
    "def get_embedding_matrix(word2embeddings):\n",
    "    embedding_dim = len(list(word2embeddings.values())[0])\n",
    "    embedding_matrix = np.zeros(shape=(len(word2embeddings)+2, embedding_dim)) # +2 as keras tokenizer is 1-based\n",
    "    for i, w in enumerate(word2embeddings): # keras' tokenizer index is 1-based\n",
    "        embedding_matrix[i+1] = word2embeddings[w]\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_corpus: processing [data/parsed/parsed-12heads.txt]\n",
      "read_corpus: processing [data/parsed/parsed-1893.txt]\n",
      "read_corpus: processing [data/parsed/parsed-20160221-thesueno-utf8.txt]\n",
      "read_corpus: processing [data/parsed/parsed-20160221-thesueno.txt]\n",
      "read_corpus: processing [data/parsed/parsed-3card-deadmanshill-2016Ap24.txt]\n",
      "read_corpus: processing [data/parsed/parsed-69krakatoa.txt]\n",
      "read_corpus: processing [data/parsed/parsed-905-shrapnel.txt]\n",
      "read_corpus: processing [data/parsed/parsed-abno.txt]\n",
      "read_corpus: processing [data/parsed/parsed-acg-crossbow.txt]\n",
      "read_corpus: processing [data/parsed/parsed-acitw.txt]\n",
      "read_corpus: processing [data/parsed/parsed-actofmurder.txt]\n",
      "read_corpus: processing [data/parsed/parsed-adverbum.txt]\n",
      "read_corpus: processing [data/parsed/parsed-afdfr.txt]\n",
      "read_corpus: processing [data/parsed/parsed-afflicted.txt]\n",
      "read_corpus: processing [data/parsed/parsed-allthingsdevours.txt]\n",
      "read_corpus: processing [data/parsed/parsed-aotearoa.txt]\n",
      "read_corpus: processing [data/parsed/parsed-awakening.txt]\n",
      "read_corpus: processing [data/parsed/parsed-beingandrewplotkin.txt]\n",
      "read_corpus: processing [data/parsed/parsed-bellwater.txt]\n",
      "read_corpus: processing [data/parsed/parsed-bestman.txt]\n",
      "read_corpus: processing [data/parsed/parsed-blindhouse.txt]\n",
      "read_corpus: processing [data/parsed/parsed-bonaventure.txt]\n",
      "read_corpus: processing [data/parsed/parsed-bookvol.txt]\n",
      "read_corpus: processing [data/parsed/parsed-broadsides.txt]\n",
      "read_corpus: processing [data/parsed/parsed-bryant.txt]\n",
      "read_corpus: processing [data/parsed/parsed-bse.txt]\n",
      "read_corpus: processing [data/parsed/parsed-buddha.txt]\n",
      "read_corpus: processing [data/parsed/parsed-cacophony.txt]\n",
      "read_corpus: processing [data/parsed/parsed-cc-fangvclaw-flooby.txt]\n",
      "read_corpus: processing [data/parsed/parsed-chefjanitor.txt]\n",
      "read_corpus: processing [data/parsed/parsed-childsplay.txt]\n",
      "read_corpus: processing [data/parsed/parsed-chineseroom.txt]\n",
      "read_corpus: processing [data/parsed/parsed-clipperbeta.txt]\n",
      "read_corpus: processing [data/parsed/parsed-cokeandspeed.txt]\n",
      "read_corpus: processing [data/parsed/parsed-cove.txt]\n",
      "read_corpus: processing [data/parsed/parsed-crescent.txt]\n",
      "read_corpus: processing [data/parsed/parsed-csbb.txt]\n",
      "read_corpus: processing [data/parsed/parsed-cull.txt]\n",
      "read_corpus: processing [data/parsed/parsed-death.txt]\n",
      "read_corpus: processing [data/parsed/parsed-defra.txt]\n",
      "read_corpus: processing [data/parsed/parsed-degeneracy.txt]\n",
      "read_corpus: processing [data/parsed/parsed-demoparty.txt]\n",
      "read_corpus: processing [data/parsed/parsed-dialcforcupcakes-103014.txt]\n",
      "read_corpus: processing [data/parsed/parsed-divis.txt]\n",
      "read_corpus: processing [data/parsed/parsed-djinni.txt]\n",
      "read_corpus: processing [data/parsed/parsed-dramaqueen.txt]\n",
      "read_corpus: processing [data/parsed/parsed-dualtransform.txt]\n",
      "read_corpus: processing [data/parsed/parsed-eas.txt]\n",
      "read_corpus: processing [data/parsed/parsed-eas2.txt]\n",
      "read_corpus: processing [data/parsed/parsed-eatme.txt]\n",
      "read_corpus: processing [data/parsed/parsed-edifice.txt]\n",
      "read_corpus: processing [data/parsed/parsed-electric.txt]\n",
      "read_corpus: processing [data/parsed/parsed-elysium.txt]\n",
      "read_corpus: processing [data/parsed/parsed-envcomp.txt]\n",
      "read_corpus: processing [data/parsed/parsed-escapade.txt]\n",
      "read_corpus: processing [data/parsed/parsed-eurydice.txt]\n",
      "read_corpus: processing [data/parsed/parsed-everybodydies.txt]\n",
      "read_corpus: processing [data/parsed/parsed-everybodylovesaparade.txt]\n",
      "read_corpus: processing [data/parsed/parsed-fdb-tin-folkar.txt]\n",
      "read_corpus: processing [data/parsed/parsed-fear.txt]\n",
      "read_corpus: processing [data/parsed/parsed-fifteenminutes-100214.txt]\n",
      "read_corpus: processing [data/parsed/parsed-finalexam20160124.txt]\n",
      "read_corpus: processing [data/parsed/parsed-finetuned.txt]\n",
      "read_corpus: processing [data/parsed/parsed-firebird.txt]\n",
      "read_corpus: processing [data/parsed/parsed-fish.txt]\n",
      "read_corpus: processing [data/parsed/parsed-floatpoint.txt]\n",
      "read_corpus: processing [data/parsed/parsed-foofoo.txt]\n",
      "read_corpus: processing [data/parsed/parsed-forachange.txt]\n",
      "read_corpus: processing [data/parsed/parsed-foth.txt]\n",
      "read_corpus: processing [data/parsed/parsed-fragileshells.txt]\n",
      "read_corpus: processing [data/parsed/parsed-ft-n-awe.txt]\n",
      "read_corpus: processing [data/parsed/parsed-galatea.txt]\n",
      "read_corpus: processing [data/parsed/parsed-gdc09.txt]\n",
      "read_corpus: processing [data/parsed/parsed-glowgrass.txt]\n",
      "read_corpus: processing [data/parsed/parsed-goldilocks.txt]\n",
      "read_corpus: processing [data/parsed/parsed-groovebillygoat.txt]\n",
      "read_corpus: processing [data/parsed/parsed-ground.txt]\n",
      "read_corpus: processing [data/parsed/parsed-guesstheverb.txt]\n",
      "read_corpus: processing [data/parsed/parsed-halothane.txt]\n",
      "read_corpus: processing [data/parsed/parsed-hamper.txt]\n",
      "read_corpus: processing [data/parsed/parsed-heroes.txt]\n",
      "read_corpus: processing [data/parsed/parsed-hollywoodvisionary-part1-utf8.txt]\n",
      "read_corpus: processing [data/parsed/parsed-hollywoodvisionary-part1.txt]\n",
      "read_corpus: processing [data/parsed/parsed-hollywoodvisionary-part2-utf8.txt]\n",
      "read_corpus: processing [data/parsed/parsed-hollywoodvisionary-part2.txt]\n",
      "read_corpus: processing [data/parsed/parsed-hoosegow.txt]\n",
      "read_corpus: processing [data/parsed/parsed-houseofdreamofmoon.txt]\n",
      "read_corpus: processing [data/parsed/parsed-hunterindarkness.txt]\n",
      "read_corpus: processing [data/parsed/parsed-ic1701.txt]\n",
      "read_corpus: processing [data/parsed/parsed-ic1702.txt]\n",
      "read_corpus: processing [data/parsed/parsed-ic1703.txt]\n",
      "read_corpus: processing [data/parsed/parsed-ic1704.txt]\n",
      "read_corpus: processing [data/parsed/parsed-ic2010-1.txt]\n",
      "read_corpus: processing [data/parsed/parsed-indigo.txt]\n",
      "read_corpus: processing [data/parsed/parsed-inls.txt]\n",
      "read_corpus: processing [data/parsed/parsed-introcomp.txt]\n",
      "read_corpus: processing [data/parsed/parsed-introcomp08a.txt]\n",
      "read_corpus: processing [data/parsed/parsed-introcomp11.txt]\n",
      "read_corpus: processing [data/parsed/parsed-introcomp2.txt]\n",
      "read_corpus: processing [data/parsed/parsed-invisargo.txt]\n",
      "read_corpus: processing [data/parsed/parsed-jabberwocky.txt]\n",
      "read_corpus: processing [data/parsed/parsed-jacket4.txt]\n",
      "read_corpus: processing [data/parsed/parsed-jacqissick.txt]\n",
      "read_corpus: processing [data/parsed/parsed-jfw.txt]\n",
      "read_corpus: processing [data/parsed/parsed-ka.txt]\n",
      "read_corpus: processing [data/parsed/parsed-laidoff-1May2016.txt]\n",
      "read_corpus: processing [data/parsed/parsed-laidoff-subrosa-1May2016.txt]\n",
      "read_corpus: processing [data/parsed/parsed-lethe.txt]\n",
      "read_corpus: processing [data/parsed/parsed-littlebluemen.txt]\n",
      "read_corpus: processing [data/parsed/parsed-lmwh.txt]\n",
      "read_corpus: processing [data/parsed/parsed-loose.txt]\n",
      "read_corpus: processing [data/parsed/parsed-lostpig.txt]\n",
      "read_corpus: processing [data/parsed/parsed-luminous.txt]\n",
      "read_corpus: processing [data/parsed/parsed-maincourse-iamthelaw.txt]\n",
      "read_corpus: processing [data/parsed/parsed-marika.txt]\n",
      "read_corpus: processing [data/parsed/parsed-measure.txt]\n",
      "read_corpus: processing [data/parsed/parsed-metamorphoses.txt]\n",
      "read_corpus: processing [data/parsed/parsed-mingsheng.txt]\n",
      "read_corpus: processing [data/parsed/parsed-mite.txt]\n",
      "read_corpus: processing [data/parsed/parsed-monkfish.txt]\n",
      "read_corpus: processing [data/parsed/parsed-moonlittower.txt]\n",
      "read_corpus: processing [data/parsed/parsed-mugglestudies.txt]\n",
      "read_corpus: processing [data/parsed/parsed-newernewyear.txt]\n",
      "read_corpus: processing [data/parsed/parsed-newyearsspeed-jan16a.txt]\n",
      "read_corpus: processing [data/parsed/parsed-newyearsspeed-jan16b.txt]\n",
      "read_corpus: processing [data/parsed/parsed-newyearsspeed-jan9.txt]\n",
      "read_corpus: processing [data/parsed/parsed-newyearsspeed.txt]\n",
      "read_corpus: processing [data/parsed/parsed-newyearsspeed08.txt]\n",
      "read_corpus: processing [data/parsed/parsed-nightfall.txt]\n",
      "read_corpus: processing [data/parsed/parsed-nightfall2.txt]\n",
      "read_corpus: processing [data/parsed/parsed-nordandbert.txt]\n",
      "read_corpus: processing [data/parsed/parsed-oad.txt]\n",
      "read_corpus: processing [data/parsed/parsed-oneeyeopen.txt]\n",
      "read_corpus: processing [data/parsed/parsed-onehalf.txt]\n",
      "read_corpus: processing [data/parsed/parsed-orevore.txt]\n",
      "read_corpus: processing [data/parsed/parsed-park.txt]\n",
      "read_corpus: processing [data/parsed/parsed-partyfoul.txt]\n",
      "read_corpus: processing [data/parsed/parsed-pathway.txt]\n",
      "read_corpus: processing [data/parsed/parsed-pax.txt]\n",
      "read_corpus: processing [data/parsed/parsed-pax2.txt]\n",
      "read_corpus: processing [data/parsed/parsed-pax2011.txt]\n",
      "read_corpus: processing [data/parsed/parsed-pepper.txt]\n",
      "read_corpus: processing [data/parsed/parsed-photograph.txr.txt]\n",
      "read_corpus: processing [data/parsed/parsed-photograph.txt]\n",
      "read_corpus: processing [data/parsed/parsed-plan6-waker.txt]\n",
      "read_corpus: processing [data/parsed/parsed-plunderedhearts.txt]\n",
      "read_corpus: processing [data/parsed/parsed-pnnsi1.txt]\n",
      "read_corpus: processing [data/parsed/parsed-pnnsi2.txt]\n",
      "read_corpus: processing [data/parsed/parsed-primrose-edited.txt]\n",
      "read_corpus: processing [data/parsed/parsed-progressive1.txt]\n",
      "read_corpus: processing [data/parsed/parsed-punkpoints.txt]\n",
      "read_corpus: processing [data/parsed/parsed-rameses.txt]\n",
      "read_corpus: processing [data/parsed/parsed-recluse.txt]\n",
      "read_corpus: processing [data/parsed/parsed-represso.txt]\n",
      "read_corpus: processing [data/parsed/parsed-revolution-buny.txt]\n",
      "read_corpus: processing [data/parsed/parsed-robot.txt]\n",
      "read_corpus: processing [data/parsed/parsed-rogue.txt]\n",
      "read_corpus: processing [data/parsed/parsed-roofed-alien.txt]\n",
      "read_corpus: processing [data/parsed/parsed-rover.txt]\n",
      "read_corpus: processing [data/parsed/parsed-samfortune.txt]\n",
      "read_corpus: processing [data/parsed/parsed-santaland.txt]\n",
      "read_corpus: processing [data/parsed/parsed-saugusnet-a.txt]\n",
      "read_corpus: processing [data/parsed/parsed-saugusnet-b.txt]\n",
      "read_corpus: processing [data/parsed/parsed-saugusnet-c.txt]\n",
      "read_corpus: processing [data/parsed/parsed-scaryhouseamulet.txt]\n",
      "read_corpus: processing [data/parsed/parsed-scavenger.txt]\n",
      "read_corpus: processing [data/parsed/parsed-sequitur.txt]\n",
      "read_corpus: processing [data/parsed/parsed-shadowsonthemirror.txt]\n",
      "read_corpus: processing [data/parsed/parsed-shelter.txt]\n",
      "read_corpus: processing [data/parsed/parsed-sherbet.txt]\n",
      "read_corpus: processing [data/parsed/parsed-simplethefts.txt]\n",
      "read_corpus: processing [data/parsed/parsed-sinsagainstmimesis.txt]\n",
      "read_corpus: processing [data/parsed/parsed-six.txt]\n",
      "read_corpus: processing [data/parsed/parsed-smittenkittens.txt]\n",
      "read_corpus: processing [data/parsed/parsed-snacktime.txt]\n",
      "read_corpus: processing [data/parsed/parsed-softfood.txt]\n",
      "read_corpus: processing [data/parsed/parsed-sorcerer.txt]\n",
      "read_corpus: processing [data/parsed/parsed-spring.txt]\n",
      "read_corpus: processing [data/parsed/parsed-spur.txt]\n",
      "read_corpus: processing [data/parsed/parsed-ssi.txt]\n",
      "read_corpus: processing [data/parsed/parsed-ssos.txt]\n",
      "read_corpus: processing [data/parsed/parsed-starborn.txt]\n",
      "read_corpus: processing [data/parsed/parsed-statue.txt]\n",
      "read_corpus: processing [data/parsed/parsed-stewie-escapade.txt]\n",
      "read_corpus: processing [data/parsed/parsed-stf.txt]\n",
      "read_corpus: processing [data/parsed/parsed-subrosa-1and8may2016.txt]\n",
      "read_corpus: processing [data/parsed/parsed-suspended.txt]\n",
      "read_corpus: processing [data/parsed/parsed-suvehnux.txt]\n",
      "read_corpus: processing [data/parsed/parsed-swigian.txt]\n",
      "read_corpus: processing [data/parsed/parsed-tacofiction.txt]\n",
      "read_corpus: processing [data/parsed/parsed-tangle.txt]\n",
      "read_corpus: processing [data/parsed/parsed-tangle2.txt]\n",
      "read_corpus: processing [data/parsed/parsed-tapestry.txt]\n",
      "read_corpus: processing [data/parsed/parsed-tdmamoom.txt]\n",
      "read_corpus: processing [data/parsed/parsed-thanksgiving.txt]\n",
      "read_corpus: processing [data/parsed/parsed-themultidimensionalthief.txt]\n",
      "read_corpus: processing [data/parsed/parsed-theone.txt]\n",
      "read_corpus: processing [data/parsed/parsed-theoracle.txt]\n",
      "read_corpus: processing [data/parsed/parsed-theplay.txt]\n",
      "read_corpus: processing [data/parsed/parsed-thohc1.txt]\n",
      "read_corpus: processing [data/parsed/parsed-thohc2.txt]\n",
      "read_corpus: processing [data/parsed/parsed-thread.txt]\n",
      "read_corpus: processing [data/parsed/parsed-tokyo-mouse.txt]\n",
      "read_corpus: processing [data/parsed/parsed-toonesiabandit.txt]\n",
      "read_corpus: processing [data/parsed/parsed-transparent-100914.txt]\n",
      "read_corpus: processing [data/parsed/parsed-tryst.txt]\n",
      "read_corpus: processing [data/parsed/parsed-turkeyspeeds.txt]\n",
      "read_corpus: processing [data/parsed/parsed-unclezeb.txt]\n",
      "read_corpus: processing [data/parsed/parsed-undertow.txt]\n",
      "read_corpus: processing [data/parsed/parsed-unipool.txt]\n",
      "read_corpus: processing [data/parsed/parsed-unscientific.txt]\n",
      "read_corpus: processing [data/parsed/parsed-vagueness.txt]\n",
      "read_corpus: processing [data/parsed/parsed-varkana.txt]\n",
      "read_corpus: processing [data/parsed/parsed-violet.txt]\n",
      "read_corpus: processing [data/parsed/parsed-wand.txt]\n",
      "read_corpus: processing [data/parsed/parsed-weapon.txt]\n",
      "read_corpus: processing [data/parsed/parsed-wedding.txt]\n",
      "read_corpus: processing [data/parsed/parsed-windjack.txt]\n",
      "read_corpus: processing [data/parsed/parsed-winterwonderland.txt]\n",
      "read_corpus: processing [data/parsed/parsed-wishbringer.txt]\n",
      "read_corpus: processing [data/parsed/parsed-wizard.txt]\n",
      "read_corpus: processing [data/parsed/parsed-wof-sa.txt]\n",
      "read_corpus: processing [data/parsed/parsed-ww-jingo-madrigals.txt]\n",
      "read_corpus: processing [data/parsed/parsed-xyzzy2011.txt]\n",
      "read_corpus: processing [data/parsed/parsed-yakshaving.txt]\n",
      "read_corpus: processing [data/parsed/parsed-yetifail.txt]\n",
      "read_corpus: processing [data/parsed/parsed-zork-i-2016-04-0310.txt]\n",
      "read_corpus: processing [data/parsed/parsed-zork1+troll-2016Ap0310.txt]\n",
      "read_corpus: processing [data/parsed/parsed-zorkII.txt]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'w2v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-0d4f9fd0bf0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moov_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munk_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'w2v' is not defined"
     ]
    }
   ],
   "source": [
    "corpus = read_corpus(file_list)\n",
    "tokenizer, index_word = build_vocabulary(corpus, num_words=20000, oov_token=unk_token)\n",
    "embedding_matrix, missing_words = get_embeddings(tokenizer.word_index, w2v, unk_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 20002\n",
      "OOV token index: 20001\n",
      "EOS token index: 20002\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary size:', tokenizer.num_words)\n",
    "print('OOV token index:', tokenizer.word_index[unk_token])\n",
    "print('EOS token index:', tokenizer.word_index[eos_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix size: (20003, 300)\n",
      "Total triples: 131807\n",
      "Unique words found (UNK, EOS + vocab): 20002\n",
      "Of which missing words (no embeddings): 1557\n"
     ]
    }
   ],
   "source": [
    "# text = 'Sample sentence with a possible balabiut token and some 1984 plus sentry'\n",
    "# print(preprocess(text))\n",
    "# print(prepare_input(text, tokenizer))\n",
    "vocab_size = len(embedding_matrix)\n",
    "unk_index = tokenizer.word_index[unk_token]\n",
    "eos_index = unk_index+1\n",
    "print('Embedding matrix size:', embedding_matrix.shape)\n",
    "print('Total triples:', sum([(len(f)-3)//2 for f in data]))\n",
    "print('Unique words found (UNK, EOS + vocab):', len(tokenizer.word_index))\n",
    "print('Of which missing words (no embeddings):', len(missing_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_data: processing [data/parsed/parsed-12heads.txt]\n",
      "prepare_data: processing [data/parsed/parsed-1893.txt]\n",
      "Line 1197 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-20160221-thesueno-utf8.txt]\n",
      "prepare_data: processing [data/parsed/parsed-20160221-thesueno.txt]\n",
      "Line 1445 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-3card-deadmanshill-2016Ap24.txt]\n",
      "prepare_data: processing [data/parsed/parsed-69krakatoa.txt]\n",
      "prepare_data: processing [data/parsed/parsed-905-shrapnel.txt]\n",
      "prepare_data: processing [data/parsed/parsed-abno.txt]\n",
      "Line 1217 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-acg-crossbow.txt]\n",
      "Line 1825 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-acitw.txt]\n",
      "prepare_data: processing [data/parsed/parsed-actofmurder.txt]\n",
      "Line 567 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-adverbum.txt]\n",
      "Line 1085 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-afdfr.txt]\n",
      "prepare_data: processing [data/parsed/parsed-afflicted.txt]\n",
      "prepare_data: processing [data/parsed/parsed-allthingsdevours.txt]\n",
      "prepare_data: processing [data/parsed/parsed-aotearoa.txt]\n",
      "prepare_data: processing [data/parsed/parsed-awakening.txt]\n",
      "prepare_data: processing [data/parsed/parsed-beingandrewplotkin.txt]\n",
      "Line 833 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-bellwater.txt]\n",
      "prepare_data: processing [data/parsed/parsed-bestman.txt]\n",
      "Line 1509 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-blindhouse.txt]\n",
      "prepare_data: processing [data/parsed/parsed-bonaventure.txt]\n",
      "Line 759 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-bookvol.txt]\n",
      "Line 393 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-broadsides.txt]\n",
      "prepare_data: processing [data/parsed/parsed-bryant.txt]\n",
      "Line 995 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-bse.txt]\n",
      "prepare_data: processing [data/parsed/parsed-buddha.txt]\n",
      "Line 661 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-cacophony.txt]\n",
      "prepare_data: processing [data/parsed/parsed-cc-fangvclaw-flooby.txt]\n",
      "prepare_data: processing [data/parsed/parsed-chefjanitor.txt]\n",
      "Line 871 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-childsplay.txt]\n",
      "Line 2191 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-chineseroom.txt]\n",
      "prepare_data: processing [data/parsed/parsed-clipperbeta.txt]\n",
      "prepare_data: processing [data/parsed/parsed-cokeandspeed.txt]\n",
      "prepare_data: processing [data/parsed/parsed-cove.txt]\n",
      "prepare_data: processing [data/parsed/parsed-crescent.txt]\n",
      "prepare_data: processing [data/parsed/parsed-csbb.txt]\n",
      "prepare_data: processing [data/parsed/parsed-cull.txt]\n",
      "Line 2031 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-death.txt]\n",
      "prepare_data: processing [data/parsed/parsed-defra.txt]\n",
      "prepare_data: processing [data/parsed/parsed-degeneracy.txt]\n",
      "prepare_data: processing [data/parsed/parsed-demoparty.txt]\n",
      "Line 665 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-dialcforcupcakes-103014.txt]\n",
      "prepare_data: processing [data/parsed/parsed-divis.txt]\n",
      "prepare_data: processing [data/parsed/parsed-djinni.txt]\n",
      "Line 891 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-dramaqueen.txt]\n",
      "prepare_data: processing [data/parsed/parsed-dualtransform.txt]\n",
      "prepare_data: processing [data/parsed/parsed-eas.txt]\n",
      "Line 363 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-eas2.txt]\n",
      "prepare_data: processing [data/parsed/parsed-eatme.txt]\n",
      "prepare_data: processing [data/parsed/parsed-edifice.txt]\n",
      "prepare_data: processing [data/parsed/parsed-electric.txt]\n",
      "prepare_data: processing [data/parsed/parsed-elysium.txt]\n",
      "prepare_data: processing [data/parsed/parsed-envcomp.txt]\n",
      "prepare_data: processing [data/parsed/parsed-escapade.txt]\n",
      "prepare_data: processing [data/parsed/parsed-eurydice.txt]\n",
      "prepare_data: processing [data/parsed/parsed-everybodydies.txt]\n",
      "Line 459 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-everybodylovesaparade.txt]\n",
      "prepare_data: processing [data/parsed/parsed-fdb-tin-folkar.txt]\n",
      "prepare_data: processing [data/parsed/parsed-fear.txt]\n",
      "Line 1897 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-fifteenminutes-100214.txt]\n",
      "prepare_data: processing [data/parsed/parsed-finalexam20160124.txt]\n",
      "Line 1723 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-finetuned.txt]\n",
      "prepare_data: processing [data/parsed/parsed-firebird.txt]\n",
      "Line 1877 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-fish.txt]\n",
      "Line 2983 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-floatpoint.txt]\n",
      "prepare_data: processing [data/parsed/parsed-foofoo.txt]\n",
      "prepare_data: processing [data/parsed/parsed-forachange.txt]\n",
      "prepare_data: processing [data/parsed/parsed-foth.txt]\n",
      "prepare_data: processing [data/parsed/parsed-fragileshells.txt]\n",
      "prepare_data: processing [data/parsed/parsed-ft-n-awe.txt]\n",
      "Line 1875 is empty. Replacing with \"empty line\".\n",
      "Line 2021 is empty. Replacing with \"empty line\".\n",
      "Line 2325 is empty. Replacing with \"empty line\".\n",
      "Line 2545 is empty. Replacing with \"empty line\".\n",
      "Line 3249 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-galatea.txt]\n",
      "prepare_data: processing [data/parsed/parsed-gdc09.txt]\n",
      "prepare_data: processing [data/parsed/parsed-glowgrass.txt]\n",
      "prepare_data: processing [data/parsed/parsed-goldilocks.txt]\n",
      "prepare_data: processing [data/parsed/parsed-groovebillygoat.txt]\n",
      "Line 675 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-ground.txt]\n",
      "prepare_data: processing [data/parsed/parsed-guesstheverb.txt]\n",
      "prepare_data: processing [data/parsed/parsed-halothane.txt]\n",
      "prepare_data: processing [data/parsed/parsed-hamper.txt]\n",
      "prepare_data: processing [data/parsed/parsed-heroes.txt]\n",
      "Line 2197 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-hollywoodvisionary-part1-utf8.txt]\n",
      "prepare_data: processing [data/parsed/parsed-hollywoodvisionary-part1.txt]\n",
      "prepare_data: processing [data/parsed/parsed-hollywoodvisionary-part2-utf8.txt]\n",
      "prepare_data: processing [data/parsed/parsed-hollywoodvisionary-part2.txt]\n",
      "prepare_data: processing [data/parsed/parsed-hoosegow.txt]\n",
      "prepare_data: processing [data/parsed/parsed-houseofdreamofmoon.txt]\n",
      "prepare_data: processing [data/parsed/parsed-hunterindarkness.txt]\n",
      "prepare_data: processing [data/parsed/parsed-ic1701.txt]\n",
      "prepare_data: processing [data/parsed/parsed-ic1702.txt]\n",
      "Line 135 is empty. Replacing with \"empty line\".\n",
      "Line 139 is empty. Replacing with \"empty line\".\n",
      "Line 165 is empty. Replacing with \"empty line\".\n",
      "Line 201 is empty. Replacing with \"empty line\".\n",
      "Line 205 is empty. Replacing with \"empty line\".\n",
      "Line 209 is empty. Replacing with \"empty line\".\n",
      "Line 213 is empty. Replacing with \"empty line\".\n",
      "Line 217 is empty. Replacing with \"empty line\".\n",
      "Line 221 is empty. Replacing with \"empty line\".\n",
      "Line 225 is empty. Replacing with \"empty line\".\n",
      "Line 229 is empty. Replacing with \"empty line\".\n",
      "Line 233 is empty. Replacing with \"empty line\".\n",
      "Line 237 is empty. Replacing with \"empty line\".\n",
      "Line 241 is empty. Replacing with \"empty line\".\n",
      "Line 249 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-ic1703.txt]\n",
      "prepare_data: processing [data/parsed/parsed-ic1704.txt]\n",
      "prepare_data: processing [data/parsed/parsed-ic2010-1.txt]\n",
      "prepare_data: processing [data/parsed/parsed-indigo.txt]\n",
      "prepare_data: processing [data/parsed/parsed-inls.txt]\n",
      "prepare_data: processing [data/parsed/parsed-introcomp.txt]\n",
      "prepare_data: processing [data/parsed/parsed-introcomp08a.txt]\n",
      "prepare_data: processing [data/parsed/parsed-introcomp11.txt]\n",
      "prepare_data: processing [data/parsed/parsed-introcomp2.txt]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_data: processing [data/parsed/parsed-invisargo.txt]\n",
      "Line 89 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-jabberwocky.txt]\n",
      "prepare_data: processing [data/parsed/parsed-jacket4.txt]\n",
      "prepare_data: processing [data/parsed/parsed-jacqissick.txt]\n",
      "prepare_data: processing [data/parsed/parsed-jfw.txt]\n",
      "Line 27 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-ka.txt]\n",
      "prepare_data: processing [data/parsed/parsed-laidoff-1May2016.txt]\n",
      "prepare_data: processing [data/parsed/parsed-laidoff-subrosa-1May2016.txt]\n",
      "Line 539 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-lethe.txt]\n",
      "prepare_data: processing [data/parsed/parsed-littlebluemen.txt]\n",
      "prepare_data: processing [data/parsed/parsed-lmwh.txt]\n",
      "prepare_data: processing [data/parsed/parsed-loose.txt]\n",
      "Line 675 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-lostpig.txt]\n",
      "prepare_data: processing [data/parsed/parsed-luminous.txt]\n",
      "prepare_data: processing [data/parsed/parsed-maincourse-iamthelaw.txt]\n",
      "Line 843 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-marika.txt]\n",
      "prepare_data: processing [data/parsed/parsed-measure.txt]\n",
      "prepare_data: processing [data/parsed/parsed-metamorphoses.txt]\n",
      "prepare_data: processing [data/parsed/parsed-mingsheng.txt]\n",
      "prepare_data: processing [data/parsed/parsed-mite.txt]\n",
      "Line 495 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-monkfish.txt]\n",
      "Line 1249 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-moonlittower.txt]\n",
      "prepare_data: processing [data/parsed/parsed-mugglestudies.txt]\n",
      "Line 249 is empty. Replacing with \"empty line\".\n",
      "Line 385 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-newernewyear.txt]\n",
      "prepare_data: processing [data/parsed/parsed-newyearsspeed-jan16a.txt]\n",
      "prepare_data: processing [data/parsed/parsed-newyearsspeed-jan16b.txt]\n",
      "prepare_data: processing [data/parsed/parsed-newyearsspeed-jan9.txt]\n",
      "prepare_data: processing [data/parsed/parsed-newyearsspeed.txt]\n",
      "prepare_data: processing [data/parsed/parsed-newyearsspeed08.txt]\n",
      "prepare_data: processing [data/parsed/parsed-nightfall.txt]\n",
      "prepare_data: processing [data/parsed/parsed-nightfall2.txt]\n",
      "prepare_data: processing [data/parsed/parsed-nordandbert.txt]\n",
      "prepare_data: processing [data/parsed/parsed-oad.txt]\n",
      "prepare_data: processing [data/parsed/parsed-oneeyeopen.txt]\n",
      "prepare_data: processing [data/parsed/parsed-onehalf.txt]\n",
      "prepare_data: processing [data/parsed/parsed-orevore.txt]\n",
      "prepare_data: processing [data/parsed/parsed-park.txt]\n",
      "Line 791 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-partyfoul.txt]\n",
      "prepare_data: processing [data/parsed/parsed-pathway.txt]\n",
      "Line 411 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-pax.txt]\n",
      "prepare_data: processing [data/parsed/parsed-pax2.txt]\n",
      "prepare_data: processing [data/parsed/parsed-pax2011.txt]\n",
      "Line 1563 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-pepper.txt]\n",
      "prepare_data: processing [data/parsed/parsed-photograph.txr.txt]\n",
      "Line 1057 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-photograph.txt]\n",
      "prepare_data: processing [data/parsed/parsed-plan6-waker.txt]\n",
      "prepare_data: processing [data/parsed/parsed-plunderedhearts.txt]\n",
      "prepare_data: processing [data/parsed/parsed-pnnsi1.txt]\n",
      "prepare_data: processing [data/parsed/parsed-pnnsi2.txt]\n",
      "Line 1727 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-primrose-edited.txt]\n",
      "Line 1091 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-progressive1.txt]\n",
      "prepare_data: processing [data/parsed/parsed-punkpoints.txt]\n",
      "prepare_data: processing [data/parsed/parsed-rameses.txt]\n",
      "prepare_data: processing [data/parsed/parsed-recluse.txt]\n",
      "prepare_data: processing [data/parsed/parsed-represso.txt]\n",
      "Line 1485 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-revolution-buny.txt]\n",
      "prepare_data: processing [data/parsed/parsed-robot.txt]\n",
      "Line 581 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-rogue.txt]\n",
      "Line 1007 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-roofed-alien.txt]\n",
      "prepare_data: processing [data/parsed/parsed-rover.txt]\n",
      "Line 1341 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-samfortune.txt]\n",
      "prepare_data: processing [data/parsed/parsed-santaland.txt]\n",
      "prepare_data: processing [data/parsed/parsed-saugusnet-a.txt]\n",
      "prepare_data: processing [data/parsed/parsed-saugusnet-b.txt]\n",
      "prepare_data: processing [data/parsed/parsed-saugusnet-c.txt]\n",
      "prepare_data: processing [data/parsed/parsed-scaryhouseamulet.txt]\n",
      "prepare_data: processing [data/parsed/parsed-scavenger.txt]\n",
      "prepare_data: processing [data/parsed/parsed-sequitur.txt]\n",
      "prepare_data: processing [data/parsed/parsed-shadowsonthemirror.txt]\n",
      "Line 661 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-shelter.txt]\n",
      "Line 1353 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-sherbet.txt]\n",
      "Line 4491 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-simplethefts.txt]\n",
      "Line 791 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-sinsagainstmimesis.txt]\n",
      "prepare_data: processing [data/parsed/parsed-six.txt]\n",
      "Line 887 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-smittenkittens.txt]\n",
      "prepare_data: processing [data/parsed/parsed-snacktime.txt]\n",
      "Line 413 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-softfood.txt]\n",
      "prepare_data: processing [data/parsed/parsed-sorcerer.txt]\n",
      "prepare_data: processing [data/parsed/parsed-spring.txt]\n",
      "prepare_data: processing [data/parsed/parsed-spur.txt]\n",
      "Line 2639 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-ssi.txt]\n",
      "prepare_data: processing [data/parsed/parsed-ssos.txt]\n",
      "prepare_data: processing [data/parsed/parsed-starborn.txt]\n",
      "Line 103 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-statue.txt]\n",
      "Line 503 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-stewie-escapade.txt]\n",
      "prepare_data: processing [data/parsed/parsed-stf.txt]\n",
      "prepare_data: processing [data/parsed/parsed-subrosa-1and8may2016.txt]\n",
      "prepare_data: processing [data/parsed/parsed-suspended.txt]\n",
      "prepare_data: processing [data/parsed/parsed-suvehnux.txt]\n",
      "Line 1083 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-swigian.txt]\n",
      "prepare_data: processing [data/parsed/parsed-tacofiction.txt]\n",
      "prepare_data: processing [data/parsed/parsed-tangle.txt]\n",
      "Line 2267 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-tangle2.txt]\n",
      "prepare_data: processing [data/parsed/parsed-tapestry.txt]\n",
      "Line 1267 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-tdmamoom.txt]\n",
      "Line 1235 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-thanksgiving.txt]\n",
      "Line 651 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-themultidimensionalthief.txt]\n",
      "prepare_data: processing [data/parsed/parsed-theone.txt]\n",
      "prepare_data: processing [data/parsed/parsed-theoracle.txt]\n",
      "prepare_data: processing [data/parsed/parsed-theplay.txt]\n",
      "Line 1 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-thohc1.txt]\n",
      "prepare_data: processing [data/parsed/parsed-thohc2.txt]\n",
      "prepare_data: processing [data/parsed/parsed-thread.txt]\n",
      "Line 1153 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-tokyo-mouse.txt]\n",
      "prepare_data: processing [data/parsed/parsed-toonesiabandit.txt]\n",
      "Line 939 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-transparent-100914.txt]\n",
      "Line 1421 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-tryst.txt]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_data: processing [data/parsed/parsed-turkeyspeeds.txt]\n",
      "Line 1271 is empty. Replacing with \"empty line\".\n",
      "Line 1575 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-unclezeb.txt]\n",
      "prepare_data: processing [data/parsed/parsed-undertow.txt]\n",
      "prepare_data: processing [data/parsed/parsed-unipool.txt]\n",
      "prepare_data: processing [data/parsed/parsed-unscientific.txt]\n",
      "Line 4597 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-vagueness.txt]\n",
      "prepare_data: processing [data/parsed/parsed-varkana.txt]\n",
      "prepare_data: processing [data/parsed/parsed-violet.txt]\n",
      "prepare_data: processing [data/parsed/parsed-wand.txt]\n",
      "prepare_data: processing [data/parsed/parsed-weapon.txt]\n",
      "prepare_data: processing [data/parsed/parsed-wedding.txt]\n",
      "Line 4547 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-windjack.txt]\n",
      "prepare_data: processing [data/parsed/parsed-winterwonderland.txt]\n",
      "prepare_data: processing [data/parsed/parsed-wishbringer.txt]\n",
      "Line 651 is empty. Replacing with \"empty line\".\n",
      "prepare_data: processing [data/parsed/parsed-wizard.txt]\n",
      "prepare_data: processing [data/parsed/parsed-wof-sa.txt]\n",
      "prepare_data: processing [data/parsed/parsed-ww-jingo-madrigals.txt]\n",
      "prepare_data: processing [data/parsed/parsed-xyzzy2011.txt]\n",
      "prepare_data: processing [data/parsed/parsed-yakshaving.txt]\n",
      "prepare_data: processing [data/parsed/parsed-yetifail.txt]\n",
      "prepare_data: processing [data/parsed/parsed-zork-i-2016-04-0310.txt]\n",
      "prepare_data: processing [data/parsed/parsed-zork1+troll-2016Ap0310.txt]\n",
      "prepare_data: processing [data/parsed/parsed-zorkII.txt]\n"
     ]
    }
   ],
   "source": [
    "data = prepare_data(corpus, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save various objects for later reuse\n",
    "with open(os.path.join(DATA_PATH, 'data_20k.pkl'), 'wb') as data_file, open(os.path.join(DATA_PATH, 'params_20k.pkl'), 'wb') as params_file:\n",
    "    params = {\n",
    "        'tokenizer': tokenizer,\n",
    "        'index_word': index_word,\n",
    "        'W': embedding_matrix,\n",
    "        'w2e': word2embeddings,\n",
    "        'missing_words': missing_words\n",
    "    }\n",
    "    pkl.dump(data, data_file)\n",
    "    pkl.dump(params, params_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(seq, n=3, step=1):\n",
    "    \"Returns a sliding window (of width n) over data from the iterable\"\n",
    "    \"   s -> (s[0],...s[n-1]), (s[0+skip_n],...,s[n-1+skip_n]), ...   \"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result    \n",
    "\n",
    "    result = result[step:]\n",
    "    for elem in it:\n",
    "        result = result + (elem,)\n",
    "        if len(result) == n:\n",
    "            yield result\n",
    "            result = result[step:]\n",
    "\n",
    "def create_samples(data, test_split=0.1, shuffle=False, max_seq_length=None):    \n",
    "    samples = []\n",
    "    for i, play in enumerate(data):\n",
    "        if max_seq_length is not None:\n",
    "            chunks = [line[offset:offset+max_seq_length] \n",
    "                      for line in play \n",
    "                      for offset in range(0, len(line), max_seq_length)]\n",
    "        else:\n",
    "            chunks = play\n",
    "            \n",
    "        for scene, command, reply in window(chunks, n=3, step=2):\n",
    "#             if max_seq_length is not None:\n",
    "#                 sub_scenes  = [scene[offset:offset+max_seq_length]   for offset in range(0, len(scene),   max_seq_length)]\n",
    "#                 sub_cmds    = [command[offset:offset+max_seq_length] for offset in range(0, len(command), max_seq_length)]\n",
    "#                 sub_replies = [reply[offset:offset+max_seq_length]   for offset in range(0, len(reply),   max_seq_length)]\n",
    "                \n",
    "#                 nb_samples = \n",
    "#                 # sample a number of contextual sequences\n",
    "#                 scenes   = sub_scenes[np.random.choice(range(len(sub_scenes)), len(sub_scenes)//max_seq_length)]\n",
    "#                 commands = sub_cmds[np.random.choice(range(len(sub_cmds)), len(sub_cmds)//max_seq_length)]\n",
    "#                 replies   = sub_replies[np.random.choice(range(len(sub_replies)), len(sub_replies)//max_seq_length)]\n",
    "                \n",
    "                \n",
    "#             if len(command) > 10:\n",
    "#                 command_line = ' '.join([index_word[idx] for idx in command])\n",
    "#                 print('Found anomalous command for play {} [{}] with length {}: [{}]'.format(\n",
    "#                     i, os.path.basename(file_list[i]), len(command), command_line))\n",
    "                \n",
    "            samples.append((scene, command, reply))\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.shuffle(samples)\n",
    "        \n",
    "    if test_split is not None:\n",
    "        split = int((1-test_split) * len(samples))\n",
    "        train_samples = samples[:split]\n",
    "        test_samples = samples[split:]\n",
    "        return train_samples, test_samples\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a batch generator\n",
    "class BatchGenerator(object):\n",
    "    def __init__(self, data, vocab_size, batch_size=1, reverse_input=True, shuffle=True):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.vocab_size = vocab_size\n",
    "        self.reverse_input = reverse_input\n",
    "        self.UNK = unk_index\n",
    "        self.EOS = eos_index\n",
    "        self.PAD = 0\n",
    "        \n",
    "    def generate_batch(self): \n",
    "        # every three lines comprise a sample sequence where the first two items\n",
    "        # are the input and the last one is the output\n",
    "        i  = 1 # batch counter        \n",
    "        x_enc = []\n",
    "        x_dec = []\n",
    "        y  = []\n",
    "            \n",
    "        while True:\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(self.data)\n",
    "            \n",
    "            for j, (scene, command, reply) in enumerate(self.data):\n",
    "                if self.reverse_input:\n",
    "                    scene = scene[::-1]\n",
    "                    \n",
    "                encoder_input  = np.array(scene + command)\n",
    "                decoder_input  = np.array([self.EOS] + reply)\n",
    "                decoder_output = np.array(to_categorical(reply + [self.EOS], self.vocab_size))\n",
    "                    \n",
    "                x_enc.append(encoder_input)\n",
    "                x_dec.append(decoder_input)\n",
    "                y.append(decoder_output)\n",
    "                \n",
    "                if i == self.batch_size or j == len(data):\n",
    "                    if self.batch_size > 1:\n",
    "                        # pad and return the batch\n",
    "                        x_enc = sequence.pad_sequences(x_enc, padding='post', value=self.PAD)\n",
    "                        x_dec = sequence.pad_sequences(x_dec, padding='post', value=self.PAD)    \n",
    "                        y     = sequence.pad_sequences(y, padding='post', value=self.PAD)\n",
    "\n",
    "                    x_out, y_out = [np.array(x_enc), np.array(x_dec)], np.array(y)\n",
    "                    \n",
    "                    i = 1\n",
    "                    x_enc = []\n",
    "                    x_dec = []\n",
    "                    y = []\n",
    "\n",
    "                    yield (x_out, y_out)\n",
    "                else:\n",
    "                    i += 1 # next sample per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns train, inference_encoder and inference_decoder models\n",
    "def define_models_lstm(src_vocab_size, embedding_matrix, dst_vocab_size=None, embedding_dim=300, latent_dim=128, \n",
    "                       mask_value=0, trainable_embeddings=False, encoder_depth=1, decoder_depth=1):\n",
    "    # define training encoder. We use return_state to retrieve the hidden states for the encoder and\n",
    "    # provide them as input to the decoder\n",
    "    if dst_vocab_size is None:\n",
    "        dst_vocab_size = src_vocab_size\n",
    "        \n",
    "    encoder_inputs = Input(shape=(None,)) # timesteps, features (integer)\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "    inputs = [encoder_inputs, decoder_inputs]\n",
    "    \n",
    "    encoder_masking = Masking(mask_value=mask_value)(encoder_inputs)\n",
    "    decoder_masking = Masking(mask_value=mask_value)(decoder_inputs)\n",
    "    \n",
    "    encoder_embedding = Embedding(input_dim=src_vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], \n",
    "                               trainable=trainable_embeddings)(encoder_masking)\n",
    "    decoder_embedding = Embedding(input_dim=src_vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], \n",
    "                               trainable=trainable_embeddings)(decoder_masking)\n",
    "    \n",
    "    ######## ENCODER ########\n",
    "    encoder_lstm = LSTM(latent_dim, return_state=True, return_sequences=True)\n",
    "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    for _ in range(encoder_depth-1):  # DEPTH (the encoder need not be shared, so we can just instantiate a new LSTM object)\n",
    "        encoder_outputs, state_h, state_c = LSTM(units=latent_dim, return_sequences=True, return_state=True)(encoder_outputs)\n",
    "        encoder_states = [state_h, state_c]\n",
    "    \n",
    "    ######## DECODER ########\n",
    "    decoder_layers = []  # keep track of deep layers\n",
    "    \n",
    "    # define training decoder. It is initialized with the encoder hidden states\n",
    "    decoder_lstm = LSTM(units=latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    for _ in range(decoder_depth-1):  # DEPTH\n",
    "        lstm = LSTM(units=latent_dim, return_sequences=True, return_state=True)\n",
    "        decoder_layers.append(lstm)\n",
    "        decoder_outputs, _, _ = lstm(decoder_outputs)\n",
    "        \n",
    "    decoder_dense = Dense(dst_vocab_size, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "        \n",
    "    model = Model(inputs, decoder_outputs)\n",
    "    \n",
    "    ####### INFERENCE ENCODER #######\n",
    "    # define inference encoder\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    ####### INFERENCE DECODER #######\n",
    "    # define inference decoder\n",
    "    decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "    decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]    \n",
    "    for d in range(decoder_depth - 1):  # DEPTH\n",
    "        decoder_outputs, state_h, state_c = decoder_layers[d](decoder_outputs)\n",
    "        decoder_states = [state_h, state_c]\n",
    "    \n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    # return all models\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(loss, val_loss, color=None, fname=None, legend=False):\n",
    "        N = len(loss)\n",
    "        train_loss_plt, = plt.plot(range(0, N), loss)\n",
    "        val_loss_plt, = plt.plot(range(0, N), val_loss)\n",
    "        \n",
    "        if color is not None:\n",
    "            plt.setp(train_loss_plt, color=color, linestyle='-')\n",
    "            plt.setp(val_loss_plt, color=color, linestyle='--')\n",
    "            \n",
    "        if legend:\n",
    "            plt.legend((train_loss_plt, val_loss_plt), ('train loss', 'val loss'))\n",
    "        \n",
    "        if fname is not None:\n",
    "            plt.savefig(fname)\n",
    "        \n",
    "        return [train_loss_plt, val_loss_plt]\n",
    "\n",
    "def plot(losses, fname=None):        \n",
    "    lines = []\n",
    "    names = []\n",
    "    colors = [plt.cm.gist_ncar(i) for i in np.linspace(0, 1, len(losses))]\n",
    "    for i, (loss, val_loss) in enumerate(losses):\n",
    "        lines.extend(plot_loss(loss, val_loss, colors[i]))\n",
    "        names.extend(['{} loss'.format(i+1), '{} val loss'.format(i+1)])\n",
    "    \n",
    "    plt.legend(lines, names)\n",
    "    \n",
    "    if fname is not None:\n",
    "        plt.savefig(fname)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class InferenceModelsCheckpoint(Callback):\n",
    "    def __init__(self, models, filepath, monitor='val_loss', verbose=0):\n",
    "        self.encoder, self.decoder = models\n",
    "        self.monitor = monitor\n",
    "        self.filepath = filepath\n",
    "        self.verbose = verbose\n",
    "        self.best = np.Inf\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current < self.best:\n",
    "            filepath = self.filepath\n",
    "            if self.verbose > 0:\n",
    "                print('\\nEpoch %05d: saving model to %s' % (epoch + 1, filepath))\n",
    "                \n",
    "            self.encoder.save(filepath + '-encinf.h5')\n",
    "            self.decoder.save(filepath + '-decinf.h5')                \n",
    "            self.best = current\n",
    "\n",
    "def train_model(models, train_samples, batch_size, epochs=10, shuffle=True, n_folds=None, train_split=None, model_name=None):\n",
    "    assert not (n_folds is not None and train_split is not None), ValueError('Either n_folds or train_split should be specified, but not both.')\n",
    "    assert not (n_folds is None and train_split is None), ValueError('Either n_folds or train_split must be specified.')   \n",
    "    \n",
    "    def _run_model(train, val):\n",
    "        train_generator = BatchGenerator(train, batch_size=batch_size, vocab_size=vocab_size, reverse_input=True, shuffle=shuffle)\n",
    "        val_generator = BatchGenerator(val, batch_size=batch_size, vocab_size=vocab_size, reverse_input=True, shuffle=shuffle)\n",
    "        \n",
    "        # utils callbacks\n",
    "        checkpointer = ModelCheckpoint(filepath=model_name + '.h5', verbose=1, save_best_only=True)\n",
    "        seq2seq_cp = InferenceModelsCheckpoint(filepath=model_name, verbose=1, models=(encoder, decoder))\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1, mode='auto', \n",
    "                                      min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "        early_stop = EarlyStopping(patience=1, min_delta=0.0001, verbose=1)\n",
    "        callbacks = [checkpointer, seq2seq_cp, reduce_lr, early_stop]\n",
    "        \n",
    "        # actual train\n",
    "        history = model.fit_generator(train_generator.generate_batch(), steps_per_epoch=len(train)//batch_size, epochs=epochs, \n",
    "                            validation_data=val_generator.generate_batch(), validation_steps=len(val)//batch_size,\n",
    "                            callbacks=callbacks)\n",
    "        \n",
    "        return history\n",
    "        \n",
    "    model, encoder, decoder = models\n",
    "    train_samples = np.array(train_samples)\n",
    "    losses = []  # keep track of train and val loss for each fold\n",
    "    \n",
    "    if n_folds is None:\n",
    "        train, val = train_test_split(train_samples, train_size=train_split, shuffle=shuffle)\n",
    "        \n",
    "        history = _run_model(train, val)\n",
    "        # plot current losses\n",
    "        plot_loss(history.history['loss'], history.history['val_loss'], fname=model_name + '.png')\n",
    "    else:  \n",
    "        kfold = KFold(n_folds, shuffle=shuffle)\n",
    "        for i, (train, val) in enumerate(kfold.split(train_samples)):\n",
    "            print(\"Running fold {}/{}\".format(i+1, n_folds))\n",
    "\n",
    "            model_file = model_name + '-fold-{}'.format(i+1)\n",
    "            history = _run_model(train_samples[train], train_samples[val])\n",
    "\n",
    "            # record losses for the final plot\n",
    "            losses.append((history.history['loss'], history.history['val_loss']))\n",
    "\n",
    "        # plot losses for all folds\n",
    "        plot(losses, model_name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'basic_seq2seq_20k_200_300d_1-1_LSTM'\n",
    "# create the model\n",
    "model, encinf, decinf = define_models_lstm(src_vocab_size=vocab_size, latent_dim=300, embedding_matrix=embedding_matrix,\n",
    "                             encoder_depth=1, decoder_depth=1, trainable_embeddings=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 132060\n",
      "Test samples: 1334\n"
     ]
    }
   ],
   "source": [
    "train_samples, test_samples = create_samples(data, max_seq_length=200, test_split=0.01)\n",
    "print('Train samples:', len(train_samples))\n",
    "print('Test samples:', len(test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/sw/python-3.5.2/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3920/3920 [==============================] - 6104s 2s/step - loss: 0.8654 - categorical_accuracy: 0.0328 - val_loss: 0.8131 - val_categorical_accuracy: 0.0424\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.81312, saving model to basic_seq2seq_20k_200_300d_1-1_LSTM.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruc0029/.local/lib/python3.5/site-packages/keras/engine/topology.py:2379: UserWarning: Layer lstm_12 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_11/while/Exit_2:0' shape=(?, 300) dtype=float32>, <tf.Tensor 'lstm_11/while/Exit_3:0' shape=(?, 300) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to basic_seq2seq_20k_200_300d_1-1_LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruc0029/.local/lib/python3.5/site-packages/keras/engine/topology.py:2379: UserWarning: Layer lstm_12 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'input_23:0' shape=(?, 300) dtype=float32>, <tf.Tensor 'input_24:0' shape=(?, 300) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "1230/3920 [========>.....................] - ETA: 1:06:56 - loss: 0.7747 - categorical_accuracy: 0.0435"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3920/3920 [==============================] - 6078s 2s/step - loss: 0.7586 - categorical_accuracy: 0.0459 - val_loss: 0.7366 - val_categorical_accuracy: 0.0503\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.81312 to 0.73664, saving model to basic_seq2seq_20k_200_300d_1-1_LSTM.h5\n",
      "\n",
      "Epoch 00002: saving model to basic_seq2seq_20k_200_300d_1-1_LSTM\n",
      "Epoch 3/5\n",
      "2784/3920 [====================>.........] - ETA: 28:26 - loss: 0.7198 - categorical_accuracy: 0.0520"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3920/3920 [==============================] - 6061s 2s/step - loss: 0.6973 - categorical_accuracy: 0.0563 - val_loss: 0.7164 - val_categorical_accuracy: 0.0585\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.70842\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b46173623c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "train_model((model, encinf, decinf), train_samples, batch_size=batch_size, epochs=epochs, \n",
    "            train_split=0.95, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'basic_seq2seq_20k_100_300d_1-1_LSTM'\n",
    "model_file = model_name + '.h5'\n",
    "# create the model\n",
    "model, encinf, decinf = define_models_lstm(src_vocab_size=vocab_size, latent_dim=300, embedding_matrix=embedding_matrix,\n",
    "                             encoder_depth=1, decoder_depth=1, trainable_embeddings=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 157731\n",
      "Test samples: 1594\n"
     ]
    }
   ],
   "source": [
    "train_samples, test_samples = create_samples(data, max_seq_length=100, test_split=0.01)\n",
    "print('Train samples:', len(train_samples))\n",
    "print('Test samples:', len(test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/sw/python-3.5.2/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1170/1170 [==============================] - 1771s 2s/step - loss: 1.4571 - categorical_accuracy: 0.1212 - val_loss: 1.4295 - val_categorical_accuracy: 0.1212\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.42950, saving model to basic_seq2seq_20k_200+50_300d_1-1_LSTM.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruc0029/.local/lib/python3.5/site-packages/keras/engine/topology.py:2379: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 300) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 300) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "1170/1170 [==============================] - 1767s 2s/step - loss: 1.4005 - categorical_accuracy: 0.1268 - val_loss: 1.4137 - val_categorical_accuracy: 0.1240\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.42950 to 1.41367, saving model to basic_seq2seq_20k_200+50_300d_1-1_LSTM.h5\n",
      "Epoch 3/5\n",
      "1170/1170 [==============================] - 1764s 2s/step - loss: 1.3632 - categorical_accuracy: 0.1310 - val_loss: 1.3928 - val_categorical_accuracy: 0.1260\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.41367 to 1.39282, saving model to basic_seq2seq_20k_200+50_300d_1-1_LSTM.h5\n",
      "Epoch 4/5\n",
      "1170/1170 [==============================] - 1769s 2s/step - loss: 1.3340 - categorical_accuracy: 0.1343 - val_loss: 1.3804 - val_categorical_accuracy: 0.1279\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.39282 to 1.38038, saving model to basic_seq2seq_20k_200+50_300d_1-1_LSTM.h5\n",
      "Epoch 5/5\n",
      "1170/1170 [==============================] - 1764s 2s/step - loss: 1.3086 - categorical_accuracy: 0.1369 - val_loss: 1.3734 - val_categorical_accuracy: 0.1300\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.38038 to 1.37336, saving model to basic_seq2seq_20k_200+50_300d_1-1_LSTM.h5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Line2D' object has no attribute 'setp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-45ab2a58c9e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m train_model(model, train_samples, batch_size=batch_size, epochs=epochs, \n\u001b[0;32m----> 4\u001b[0;31m             train_split=0.95, model_name=model_name)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-6861e8ef25b9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_samples, batch_size, epochs, shuffle, n_folds, train_split, model_name)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-6861e8ef25b9>\u001b[0m in \u001b[0;36m_run_model\u001b[0;34m(train, val, model_file)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# plot current losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtrain_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-a21aeab140d8>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(losses, fname)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgist_ncar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'{} loss'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{} val loss'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-a21aeab140d8>\u001b[0m in \u001b[0;36mplot_loss\u001b[0;34m(loss, val_loss, color, fname, legend)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mtrain_loss_plt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mval_loss_plt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Line2D' object has no attribute 'setp'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd8VFX6x/HPM+khDZIAIRCS0LuGAEED0uyuFRUboCjuuuta1rZNd39b1bW7dhBZlSJYERUUkV5CC72EkBBa6C1AypzfH3cwMYZkIJO5k8zzfr3mRTL3ztwno/O9955z7j1ijEEppZR/cNhdgFJKKe/R0FdKKT+ioa+UUn5EQ18ppfyIhr5SSvkRDX2llPIjGvpKKeVHNPSVUsqPaOgrpZQfCbS7gMri4uJMcnKy3WUopVS9smzZsn3GmPia1vO50E9OTiYrK8vuMpRSql4RkTx31tPmHaWU8iM1hr6IjBWRQhFZU8N6vUSkVESGVnguSURmiMh6EVknIsm1L1kppdS5cudIfxxwWXUriEgA8DQwo9Ki8cCzxphOQG+g8BxqVEop5SE1hr4xZg5woIbV7gemUiHURaQzEGiMmel6n2PGmKJa1KqUUqqWat2mLyKJwHXA65UWtQcOicjHIrJCRJ51nRFU9R6jRSRLRLL27t1b25KUUkqdgSc6cl8EHjfGOCs9Hwj0Ax4BegGpwMiq3sAY85YxJt0Ykx4fX+OII6WUUufIE0M204GJIgIQB1whIqVAAbDSGLMVQEQ+BTKAMR7YplJKqXNQ6yN9Y0yKMSbZGJMMTAHuM8Z8CiwFYkTk9KH7IGBdbbd3JmVOw7+mr6fgoHYbKKXUmbgzZHMCsBDoICIFIjJKRH4pIr+s7nXGmDKspp3vRGQ1IMDbnii6KvkHipiwJJ9hby1i+wENfqWUqor42sTo6enp5lyvyF1dcJjbxywmIiSQCfdkkBQb7uHqlFLKN4nIMmNMek3rNagrcru1jOaDu/twvLiUYW8tJG//cbtLUkopn9KgQh+ga2I0H96dwYmSMm5+cxG5+zT4lVLqtAYX+gCdW0Tx4T0ZFJc5GfbWQnL2HrO7JKWU8gkNMvQBOiVEMeGeDErLDMPeWsSWQg1+pZRqsKEP0KF5JBNGZ2CMFfyb9xy1uySllLJVgw59gPbNIpk4OgMRuOXtRWzS4FdK+bEGH/oAbZtawe8Q4Za3FrFh9xG7S1JKKVv4RegDtImPYOLoDAIDhFvfXsy6nRr8Sin/4zehD5AaH8Gk0X0JCXRw6zuLWLvzsN0lKaWUV/lV6AMkxzVi4ugMwoMCuPXtxazZocGvlPIffhf6AK1jGzHp3r5EhARy69uLyC44ZHdJSinlFX4Z+gCtmoQzcXQGUWFB3PbOYlZu1+BXSjV8fhv6YAX/pHv70jg8mDveWczy/IN2l6SUUnXKr0MfIDEmjImjM2gSEczwMUtYllfTdMBKKVV/+X3oA7SICWPS6L7ER4YwfMwSlm7T4FdKNUwa+i7No0OZODqDZtGhjBi7hMVb99tdklJKeZyGfgXNokKZeE8GCdGhjHx3KQtzNPiVUg2LO9MljhWRQhFZU8N6vUSkVESGVno+yjXN4qu1LdYbmkaFMmF0Bi0bh3HnuCUs2LLP7pKUUspj3DnSHwdcVt0KIhIAPA3MqGLx34A5Z12ZjZpGWsGf1CScO8ctZd5mDX6lVMNQY+gbY+YANfVs3g9MBQorPikiPYFmVL0z8GlxESFMuCeDlLhGjHpvKXM27bW7JKWUqrVat+mLSCJwHfB6pecdwHPAI7Xdhl1iI0L48J4MUuMjuHt8FrM3Ftb8IqWU8mGe6Mh9EXjcGOOs9Px9wHRjTEFNbyAio0UkS0Sy9u71rSPqJo2C+fDuPrRrGsHo8cuYtWGP3SUppdQ5E2NMzSuJJAPTjDFdq1iWC4jr1zigCBgN3Aj0A5xABBAMvGaMeaK6baWnp5usrCz3/wIvOVRUzB1jlrBh9xFev60nQzo3s7skpZT6kYgsM8ak17RerY/0jTEpxphkY0wyMAW4zxjzqTHmNmNMkuv5R4DxNQW+L4sJD+b9UX3onBDFrz5Yxoy1u+0uSSmlzpo7QzYnAAuBDq6hl6NE5Jci8su6L8+3RIcHMX5UH7q0iOa+D5bz9RoNfqVU/eJW8443+WrzTkVHTpYwYuwSVhcc5pVbzufybgl2l6SU8nNea97xR1GhQYy/qzc9WsXwmwkrmJa90+6SlFLKLRr65ygyNIj37upNWlIMD0xcyeerNPiVUr5PQ78WIkICGXdnb3q2bsyDE1fw6YoddpeklFLV0tCvpUYhgYy7sxd9UmJ5ePJKPl5e42UJSillGw19DwgPDmTsyF5kpMbyu49W8VHWdrtLUkqpKmnoe0hYcABjRvTiwjZxPDY1m8lLNfiVUr5HQ9+DwoIDeGdEOpltreCfsCTf7pKUUuonGlbo+8A1B6FBAbw9PJ0BHeL5/cereX9Rnt0lKaXUjxpO6BcXwQtdYMpdsOIDOLLLtlJCgwJ4846eDOrYlD99uobxC7fZVotSSlUUaHcBHnPqKKT0hy3fwZqp1nNNu0DbQdBmMCT1haBQr5UTEhjA67en8esPlvPkZ2txOg0jL0zx2vaVUqoqDe82DMbAnjVW+Od8B/mLoKwYAsMgORPaDIK2gyGuPYjU/H61VFzq5DcfLmfGuj38+arOjMrU4FdKeZ67t2FoeKFfWfFx2DavfCewf4v1fHQraDPQOgtIvQjCGntum5WUlDm5/8MVfL12N3+8ohP39E+ts20ppfyThv6ZHMyzwn/Ld5A7B04dAXFAYrp1BtBmMCSmgSPAo5stKXPy4MSVfLl6F09c3pFfXtTGo++vlPJvGvruKCuBHcvKzwJ2LAcMhMZA6oDynUB0okc2V1rm5MFJK5mWvYtHL+3Arwe29cj7KqWUu6HfcDpyz0VAECRlWI9Bf4SiA7D1e9gyy9oJrPvUWi++o9UX0GYwJF8IQWHntLnAAAcv3nweAQ7h2W824nQa7h/czoN/kFJKVc+/Q7+y8CbQ9QbrYQwUri9vClo6Bha9BgEh0PqC8rOApp3OqkM4MMDB8zedh0OE52ZuoswYHhzSvg7/KKWUKqehfyYi0Kyz9bjgfus6gPwF5WcBM/4E/AkiW7hGBA2C1IHWjqMGAQ7hPzf2wCHCi99uxmngoSHtEC+MJlJK+TcNfXcFh0PbIdYD4HAB5MyyzgI2TIOV7wMCLc4vPwto2QsCqv6IAxzCM0O74xB4+bvNGGN4+OL2GvxKqTpVY0euiIwFrgIKjTFdq1mvF9ZcusOMMVNE5DzgdSAKKAP+YYyZVFNB9WG6xJ9xllmdwKebgnZkgXFCSJR1wdjpnUDj1j9/qdPwh09WM3Hpdu4b0IZHL+2gwa+UOmue7MgdB7wKjK9mYwHA08CMCk8XAcONMZtFpAWwTES+McYccmOb9YsjAFr1sh4DnoATB2HrD9aZQM4s60wAILatFf5tB0PrCyEkAodD+Od13RARXpudQ5kxPHFZRw1+pVSdqDH0jTFzRCS5htXuB6YCvSq8blOFn3eKSCEQDzS80K8srDF0udZ6GAP7NpefBSwfD0veBIdr5FDbwTjaDOYf13QlwAFv/rDVOvq/opMGv1LK42rdpi8iicB1wEAqhH6ldXoDwUBObbdX74hAfHvrkfErKDkJ+QtdO4FZ8O1f4Nu/4GjUlL+1Gch5HTrwr7mHKXPCn6/S4FdKeZYnOnJfBB43xjirCigRSQD+B4wwxjiregMRGQ2MBkhKSvJAST4sKNR1+4eBcAnW3UBdzUCyeSZDT0xiaCisXprMvIL+ZF52E9KqDwQG2125UqoBcOuKXFfzzrSqOnJFJBc4nfZxWG35o40xn4pIFDAb+KcxZoo7BdXLjlxPcTph10rMlu/IXzqNFkdXEyRlmOAIJKW/6wKxQRCrt3BQSv2U167INcb8eNtIERmHtXP4VESCgU+A8e4Gvt9zOCAxDUlMI6n/Izw3bRmbFk5jVGwuvfesQDZOt9ZrnFzeIZzSH0IibS1bKVV/1Bj6IjIBGADEiUgB8BQQBGCMeaOal94E9AdiRWSk67mRxpiVtSnYX4gIv7uqJ08HRnDzDznc0uth/nFbIxy531sdwqsmQtYYcARCqz7lt4xu3sPaeSilVBX8+4Zr9YAxhv/M2Mh/v8/h5vRW/Ov6bjgcAqXFsH1x+aig3dnWC8JjrSuD2w62dgSRze39A5RSXqE3XGsgRIRHLulAgAgvz9pCmTE8fUN3AgKDIaWf9RjyFzhWCDnfWzuBnFmwxtWi1qxr+VlAUl8IDLHzz1FK2UxDvx4QER6+pAMOh+tePU7Dszf2IMBRYbRURFPocbP1cDphz2rXLaNnwaLXYcHLEBTumj3M1R8Q29Yrs4cppXyHhn498uCQ9jhEeH7mJpzG8J8bexAYUEX7vcMBCT2sR7+H4dQxa/aw001Bm10XTkcnQadfQI9h0Lyb7gCU8gMa+vXMbwe3+/F+/GUGXrjpDMFfUUgEdLjMegAc3GaF/5ZvYclbsOi/0LQzdL8Zut8EUS3q/O9QStlDO3Lrqddn5/D01xu4snsCL958HkE1Bf+ZFB2AtR/DqklQsAQQa87gHrdAx6usHYZSyudpR24D96sBbQhwwD+nb8DpNLx8y/nnFvzhTaDX3dZjfw5kT7KGg35yLwQ1cjX/3AwpF3l83mCllPfpkX49987crfz9y/Vc2qUZr9ySRnCgB8boGwP5i2DVBFj7KZw6DJEJ0O1Gq/2/WZfab0Mp5VE6MbofGTMvl79NW8fFnZvx31s9FPynlZyETV9bR/9bZoKz1Or07T7M2glENvPctpRS50xD38+Mm5/LX75Yx5BOTfnvbWmEBNZBU8zxfbBmqrUD2LkcxGFdA9DjFuhwhTW7mFLKFhr6fuh/C7fx58/WMqhjU167LY3QoDpsg9+7CbInWh3ARwogOBI6X201/7TO1FtBKOVlGvp+6oPFefzxkzVc1D6eN+/oWbfBD9aFYHnzrR3A2s+g+ChEtbSGfvYYBvEd6nb7SilAQ9+vTViSz+8/Xk2/dnG8PTy97oP/tOIi2Djdav7JmQWmzJoovvsw6HoDRMR7pw6l/JCGvp+bvHQ7j3+czYVtrOAPC/bycMuje6z7/6yaaN0MzhEIbYdYR//tL7cmk1FKeYyGvmLKsgIenbKKvqmxvDMinfBgmy7L2LPOav7J/giO7oSQaOhyjdUB3CpD2/+V8gANfQXAx8sLeOSjVfROacLYkb3sC34AZxnkzrEuAFv3OZQch5gkq/mnxzCdEUypWtDQVz/6bOUOHpq0kvTWTXj3zl40CvGBC7GLj8P6adYZwNbZYJzQspd1/5+uN1hXCiul3Kahr37i81U7eWjSSs5vFcO4u3oT4QvBf9qRXbD6I6v9v3AtOIKg/aXWDqD9pToHgFJu0NBXP/Nl9i5+O3EFPVpG895dvYkMDbK7pJ/bvdoK/9UfwbE9EBoDXa+32v9b9tLbPyt1Bu6Gfo09aCIyVkQKRWRNDev1EpFSERla4bkRIrLZ9RjhXumqrlzZPYFXbzmf7ILDDB+7hCMnS+wu6eead4NL/wEPrYPbp0K7i2HlBBhzMbySBrOfhgO5dlepVL1V45G+iPQHjgHjjTFdz7BOADATOAmMNcZMEZEmQBaQDhhgGdDTGHOwuu3pkX7d+3rNbn7z4XK6tIhi/F19iA73wSP+ik4dtTp+sydC7lzAWKN+egyDLtdCWGO7K1TKdh470jfGzAEO1LDa/cBUoLDCc5cCM40xB1xBPxO4rKbtqbp3WdfmvHZbGut2HeHSF+cwa8Meu0uqXkgknH8bjPgCHloDg5+CEwdh2oPwn/YweThsmG5NFq+UqlatB0iLSCJwHfB6pUWJwPYKvxe4nqvqPUaLSJaIZO3du7e2JSk3XNKlOR/98gKiwgK5a1wWD01aycHj9SA0o1taU0D+ejGMng3po2DbfJh4CzzfEaY/CjuWWbeHVkr9jCeuinkReNwY4zzXNzDGvGWMSTfGpMfH66X63nJeqxi+uD+T3w5uxxerdnLxCz8wffUuu8tyj4h1i4fL/w2/2wC3ToaU/rDsPXh7ELzaC+Y8C4fy7a5UKZ/i1ugdEUkGplXVpi8iucDpIRVxQBEwGggDBhhj7nWt9yYw2xgzobptaZu+PdbtPMJjU1exZscRLuvSnP+7tgtNI+vhrRJOHIJ1n1kXgOXNt55rnWm1/3e+BkKj7K1PqTri0SGb1YV+pfXGudY73ZG7DEhzLV6O1ZFbbf+Ahr59SsucvDV3Ky9+u5mwoACevKoz16clIvV1mOTBPMiebHUA798CgaHQ8UrrCuA2gyDAh65VUKqWPBb6IjIBGIB1FL8HeAoIAjDGvFFp3XG4Qt/1+13AH1yL/2GMebemgjT07bel8BiPT81mWd5BBnSI55/XdaNFTJjdZZ07Y6x2/lUTrZvAnTgIjZpCt6HWBWAJPXT8v6r39OIsVStlTsP4hdt45uuNBDiE31/RkVt6JeFw1PNwLC22pn1cNdGaBrKsGOI7WZO/d7sJoqsca6CUz9PQVx6Rv7+IJz7OZkHOfjJSm/D0Dd1pHdvI7rI8o+gArPvU2gFsXwyI1RncYxh0+oU1VFSpekJDX3mMMYaJS7fzzy/XU+J08sglHbjzwhQC6vtRf0X7c8rb/w9ug6Bw6HiVtQNIHQAOL89HoNRZ0tBXHrfr8An++MkaZm0o5PykGJ4d2p22TRvY0bAx1lH/qomw9mM4eRgimkP3G60O4ObVjmVQyjYa+qpOGGP4bOVO/vLFWopOlfHAkHaM7p9KUEADnAil5CRs/saa/H3zN+AshehW0DIdEtOtG8Al9NBZwJRP0NBXdWrv0VP85fO1fLl6F50Tonj2xu50aRFtd1l15/h+WPeJdfXvjqzyi74cQdZN4lq6dgIt06Fxio4GUl6noa+84us1u/jTp2s5VFTMLy9qw/2D2xIS6Aft30f3WOFfsBQKsmDHcmsmMIDw2PIzgZY9IbEnhDbgHaLyCRr6ymsOFRXzt2nrmbq8gLZNI3hmaHfSkvzszpfOMihcb+0EdmRZO4K9G1wLBeI7/LRZqGkn7RxWHqWhr7zu+42F/PHj1ew6cpJRF6bwu0s6EBbsx8F28rB1BlCQVb4zKNpvLQuOsO4ddLpZKDEdIpvZW6+q1zT0lS2Onizh319t4IPF+bSODeff13enb5tYu8vyDcbAwdzynUBBFuzOtjqIAaKTfto30Ly7dhIrt2noK1stzNnPEx9nk7e/iNv6JPHE5R19c3pGu5WcgF3ZP+0fOOy6I7kjCBK6V+gfSIfGydpJrKqkoa9sd6K4jOdmbGTM/FwSokL5x/XdGNihqd1l+b6ju396NrBzOZQUWcvC41xnA64dQYs0vXOoAjT0lQ9Znn+Qx6Zks6XwGNenJfLkVZ2JCQ+2u6z6o6wU9q4v3wkUZMG+ja6FAvEdf9osFN9RO4n9kIa+8imnSst4ddYWXpudQ+PwYP5+bRcu65pgd1n114lD1p1Ddyxz7QyWWncPBauTODHtp81CEXqG1dBp6CuftGbHYR6bks26XUe4oltz/np1V+IjQ+wuq/4zBg5srdAstBT2rCnvJI5Jcu0AXI/m3SBQP/eGRENf+aySMidvzdnKS99uJjwkgKd+0Zlrz6vHk7X4qpITsGtV+U6gYBkcKbCWBQRbo4NOnwm0TIeY1tpJXI9p6Cuft6XwKI9OyWZF/iEGdWzKP67rSkJ0PZ6spT44stN1BXFW+ZXEpSesZY3iXdcM9HT9m6a3l65HNPRVvVDmNIxbsI1nv9lAkMPBH67sxLBerfSo31vKSqFwXYVO4qWwf7NroVhXDle8gCy+g3YS+yhPTpc4FrgKKDzDxOjXAH8DnEAp8KAxZp5r2TPAlYADmAk8YGrYoIa+f8rbf5wnpq5m4db9XNAmln9f352k2HC7y/JPJw66OoizyncEJw9Zy4IjrTOA081CiekQEW9vvQrwbOj3B44B488Q+hHAcWOMEZHuwGRjTEcRuQB4FujvWnUe8HtjzOzqtqeh77+cTtdkLdPXU+Y0PHppB0ZckNywJmupj4yxJpn58b5CS2H3GjBl1vLGyRVGCp3uJNYhud7mbugH1rSCMWaOiCRXs/xYhV8bAaf3IgYIBYIBwZpMfU9N21P+y+EQbu2TxIAO8fzhk9X837R1fLl6F0/f0J22TSPsLs9/iUBcW+tx3i3Wc8VFP+0kzltgTToPEBBiXUncshc07QwxrazRQ1EtdWfgA2oMfXeIyHXAv4CmWM05GGMWisj3wC6s0H/VGLPeE9tTDVuLmDDeHdmLT1bs4K9frOOKl+fywOB23Ns/lcCGOFlLfRQcDq37Wo/TDu+ocDuJZZD1bnknMQACkQnlO4Fo178xrayRQ9EtIUg78uuaWx25riP9aVU171Rarz/wpDFmiIi0BV4CbnYtngk8ZoyZW8XrRgOjAZKSknrm5eWdzd+gGrDCoyd56rO1fLVmN10To3jmhh50bqG3HagXykqtIaKH8uHQduvfw65/D+XDkR3l1xGc1qhpFTuF0z+30tFE1fDo6B13Q9+17lagN3AnEGqM+Zvr+SeBk8aYZ6p7vbbpq6pMX72LJz9bw6GiEu4b0IZfD/KTyVoaMmcZHN1VaadQ8ecCKDv109eENa6wE2j98x1EWIw9f4sP8FibvhsbagvkuDpy04AQYD+QD9wjIv/Cat65CHixtttT/umKbgn0TY3lb9PW8fKsLXy1ZjfPDO3O+f42WUtD4giwmnSiW0LrKpY7nXC80LUTyKtwlrAd9m2GnFnlN6I7LSTq501HFc8YwmP9/gI0d0bvTAAGAHFYHbFPYXXKYox5Q0QeB4YDJcAJ4FFjzDwRCQBewxq9Y4CvjTEP11SQHumrmny/oZA/fLKaPUdOcne/VB4a0t6/J2vxV8ZYk9Kcbi6quFM4/fOpIz99TVB4pb6ESmcNjZqCo372G+nFWapBO3KyhH9N38CEJfkkx4bz9A3d6ZOqk7WoSk4c+vkOoeJZw+mb1J0WEGKdefxkp1Dh58gEn704TUNf+YUFOft4Yupq8g8UcUdGax6/vCMRIR4ZlKb8wamjPz0zqLyDOF740/UdgRCVWKmDucJOISoRAuyZLEhDX/mNouJS/vPNJt5dkEuL6DD+eX03LmqvV4kqDyg5YXUoH8qrYgTSdqsjmgoZKg6IbFH1sNToJNew1LqZAlNDX/mdZXkHeGxKNjl7jzO0Z0v+fGVnosN1ikZVh0qLzzAsdXv5sNTTVy6fFtHsDNcpuIalBjc6p1I09JVfOllSxiuzNvPGD1tp0iiYv1/blUu7NLe7LOWvykrh6M5KO4SKZw0F4CwpX795N/jlvHPalIa+8mtrdhzm0SnZrN91hKu6J/DXq7sQG6GThigf43TCsd3lO4GAIOhy7Tm9lYa+8nslZU7emJ3DK7O20CgkgL9c3YWre7TQ2zarBsnd0K+fA1KVckNQgIP7B7dj2m8zSYptxAMTV3LP+Cx2Hz5pd2lK2UZDXzV47ZtF8vGvLuBPV3Zi7uZ9XPzCD0xamo+vneUq5Q0a+sovBDiEu/ul8s2D/emcEMXjU1dzx5glbD9QVPOLlWpANPSVX0mOa8SEezL4+7VdWZF/kEtfnMO4+bk4nXrUr/yDhr7yOw6HcHtGa2Y8fBHpyU34yxfruPmthWzde6zmFytVz2noK7+VGBPGe3f24j839mDj7qNc9tJc3vghh9Iyp92lKVVnNPSVXxMRhvZsybcPX8TADvH8+6sNXPfaAjbsPlLzi5WqhzT0lQKaRoXyxu09+e+taew8dIJfvDKPF2ZuorhUj/pVw6Khr5SLiHBl9wRmPnwRV3ZL4KXvNnP1q/NYtf2Q3aUp5TEa+kpV0qRRMC8OO58xI9I5WFTMda/N51/T13OypKzmFyvl4zT0lTqDwZ2aMeOhi7gpvRVvztnK5S/NZc6mvXpRl6rXNPSVqkZ0WBD/vqE7H9zdh1Knk+Fjl3Dzm4tYtHW/3aUpdU5qDH0RGSsihSKy5gzLrxGRbBFZKSJZIpJZYVmSiMwQkfUisk5Ekj1XulLec2HbOL59+CL+enUXtu0/zrC3FnHbO4tYlnew5hcr5UPcmRi9P3AMGG+M6VrF8gjguDHGiEh3YLIxpqNr2WzgH8aYma71nMaYaq9717tsKl93sqSM9xfl8frsHPYfL2ZAh3h+d3EHurWMtrs05cc8dpdNY8wc4EA1y4+Z8j1HI1xzh4lIZyDQGDOzwnp6oxNV74UGBXB3v1TmPDaQxy7rwIr8Q/zi1XncMz6L9bt0fL/ybR5p0xeR60RkA/AlcJfr6fbAIRH5WERWiMizIlLlNPIiMtrVNJS1d+9eT5SkVJ1rFBLIfQPaMu/xgTw0pD2LcvZz+Utz+fWHy9lSeNTu8pSqkluTqLja4qdV1bxTab3+wJPGmCEiMhQYA5wP5AOTgOnGmDHVvYc276j66lBRMW/P3cq787dxsqSMa85L5IHB7UiOO7c5T5U6G7ZMouJqCkoVkTigAFhpjNlqjCkFPgXSPLk9pXxJTHgwj17akbmPDeTufql8tWYXg5//gcemrNJbOCufUevQF5G24pp/TkTSgBBgP7AUiBGReNeqg4B1td2eUr4uNiKEP1zRiTmPDeSOjNZ8umIng56bzR8/Wc2uwyfsLk/5OXdG70wABgBxwB7gKSAIwBjzhog8DgwHSoATwKPGmHmu114MPAcIsAwYbYwprm572ryjGppdh0/w6qwtTM7ajohwa+8k7hvYhqaRoXaXphoQnRhdKR+z/UARr8zazNTlOwgKEIb3Tebe/qnERoTYXZpqADT0lfJRufuO8/J3m/l05Q7CgwIYeWEyo/u1ITo8yO7SVD2moa+Uj9tSeJQXvt3Ml9m7iAwN5O7MVO7KTCYyVMNfnT0NfaXqiXU7j/DCt5uYuW4PMeFBjO6fyoi+yTQKCbS7NFWPaOgrVc9kFxzi+ZmbmL1xL7GNgvnVgDbcntGa0KAqr2lU6ic09JWqp5blHeT5mRuZv2U/TSND+PXAtgwf2CzCAAAPG0lEQVTr3YqQQA1/dWYa+krVc4u27uf5GZtYsu0ALaJD+c2gdtyY3pKgAL0juvo5DX2lGgBjDPO27OO5GZtYuf0QrZqE8dtB7bju/EQCNfxVBbbchkEp5VkiQr928Xxy3wWMHZlOVGgQj07J5pIX5vDZyh2UOX3roE35Pg19peoBEWFQx2ZMuz+TN27vSVCAgwcmruTyl+bw1epdODX8lZs09JWqR0SEy7o256sH+vHyLedT6jT86oPlXPXKPL5dt0fn71U10tBXqh5yOISre7RgxoP9ee7GHhw7Vcrd47O49rUF/KCTt6tqaEeuUg1ASZmTqcsKeGXWFnYcOkF668Y8fEl7LmgTZ3dpykt09I5SfuhUaRmTl27n1e+3sOfIKfqmxvK7S9qTntzE7tJUHdPQV8qPnSwp44PF+bw+ewv7jhXTv308v7u4PT1axdhdmqojGvpKKYqKSxm/MI83f8jhYFEJQzo15aGL29OlRbTdpSkP09BXSv3o6MkSxs3fxltzt3L0ZClXdGvOg0Pa075ZpN2lKQ/R0FdK/czhEyWMmbuVsfO3cby4lKt7tOCBwe1IjY+wuzRVSx67IldExopIoYisOcPya0QkW0RWikiWiGRWWh4lIgUi8qr75Sul6kJ0WBAPX9KBuY8N5N7+bZixdg9Dnv+BRz7Sydv9hTtz5PYHjgHjjTFdq1geARw3xhgR6Q5MNsZ0rLD8JSAeOGCM+U1NBemRvlLes/foKd74IYf/LcrD6TTcmN6K+we1pUVMmN2lqbPksSN9Y8wc4EA1y4+Z8j1HI+DHvYiI9ASaATNqrFgp5XXxkSH8+arOzH1sILf2SWLKsu0MeHY2T322hsIjJ+0uT9UBj1yRKyLXicgG4EvgLtdzDuA54BFPbEMpVXeaRYXyf9d05ftHBnB9WiLvL86n3zPf8/dp69h37JTd5SkP8kjoG2M+cTXpXAv8zfX0fcB0Y0xBTa8XkdGu/oCsvXv3eqIkpdQ5aNk4nH/f0J1Zv7uIK7snMHZ+Lv2f+Z6nv97AwePFdpenPMCt0TsikgxMq6pNv4p1twK9gZeAfoATiACCgdeMMU9U93pt01fKd2wpPMZL321mWvZOGgUHcldmCqMyU4gO08nbfY1Hh2xWF/oi0hbIcXXkpgFfAC0rtPMjIiOBdO3IVap+2rj7KC/M3MTXa3cTFRrI6P6pjLwwhQidvN1nuBv6Nf4XE5EJwAAgTkQKgKeAIABjzBvADcBwESkBTgA3G18b/K+UqpUOzSN5446erNlxmBdmbuI/MzYxdv427u2fyvC+yYQF6/y99YVenKWUOmsr8g/y/MxNzN28j7iIEO4b0IZb+yQRGqThbxe9IlcpVeeW5B7guRkbWZx7gOZRofxmUFtuSm9FcKBO1eFtGvpKKa8wxrAgZz/PzdjI8vxDtGxsTd5+fZpO3u5NGvpKKa8yxjB7015emLmJ7ILDJMeGc9/AtlxzXgtCArXZp65p6CulbGGMYea6Pbzw7WbW7zpCXEQIw/u25rY+ScRGhNhdXoOloa+UspUxhnlb9vHO3Fx+2LSXkEAH16clcteFKbTTWzp7nMeGbCql1LkQEfq1i6dfu3g27znK2Pnb+Hh5AROWbOei9vGMykyhX7s4RMTuUv2KHukrpbxm/7FTfLg4n/cW5rHv2CnaN4tgVGYK15yXqMM9a0mbd5RSPutUaRlfrNrFmHm5rN91hNhGwdye0ZrbM1oTH6nt/udCQ18p5fOMMSzM2c+Yebl8t6GQ4AAH157fglGZqXRoru3+Z0Pb9JVSPk9EuKBtHBe0jSNn7zHenZ/LlGUFTM4qoF+7OO7KTOGidvE4HNru7yl6pK+U8ikHjxfz4ZJ83luwjcKjp2gT34hRmalcn6bt/tXR5h2lVL1WXOrky9U7GTMvlzU7jtA4PIjbM1pzR9/WNI0Mtbs8n6Ohr5RqEIwxLM49wJh5uXy7fg+BDuHqHomMykyhc4sou8vzGdqmr5RqEESEjNRYMlJjyd13nHHzc5mcVcDU5QVc0CaWUZkpDOzQVNv93aRH+kqpeudwUQkTllrt/rsOnyQ1rhF3ZqZwQ1oi4cH+eSyrzTtKqQavpMzJ9NXWeP/sgsNEhwVxW58khvdNpnm0f7X7a+grpfyGMYasvIOMmZvLN+t2EyDCL3q0YFRmCl0To+0uzyu0TV8p5TdEhF7JTeiV3IT8/UW8uyCXyUu388mKHfROacLdmSkM7tSMAG33p8YZDkRkrIgUisiaMyy/RkSyRWSliGSJSKbr+fNEZKGIrHUtv9nTxSulVGVJseE89YsuLPzDYP54RSd2HDzB6P8tY9Bzs3lvwTaOnyq1u0Rb1di8IyL9gWPAeGNM1yqWRwDHjTFGRLoDk40xHUWkPWCMMZtFpAWwDOhkjDlU3fa0eUcp5UmlZU6+XrubMfNyWZF/iKjQQG7pk8SIvsm0iAmzuzyP8VjzjjFmjogkV7P8WIVfGwHG9fymCuvsFJFCIB6oNvSVUsqTAgMcXNW9BVd1b8GyvIOMnZfL23O28s7cXK7slsCozBR6tIqxu0yv8UibvohcB/wLaApcWcXy3kAwkOOJ7Sml1Lno2boxPVs3ZvuBIt5bsI1JS7fz+aqd9EpuzKjMFC7u3LzBt/u7NXrHdaQ/rarmnUrr9QeeNMYMqfBcAjAbGGGMWXSG140GRgMkJSX1zMvLc7N8pZQ6d0dPljA5q4B35+dScPAErZqEcecFKdzUqxURIfVrnItHh2y6G/qudbcCvY0x+0QkCivw/2mMmVLjhtA2faWU95U5DTNc7f5ZeQeJDAlkWO9WjLggmZaNw+0uzy1eG7IpIm2BHFdHbhoQAuwXkWDgE6wOYLcCXyml7BDgEC7vlsDl3RJYuf0QY+blMnb+NsbO38ZlXZszKjOFtKTGdpfpEe6M3pkADADigD3AU0AQgDHmDRF5HBgOlAAngEeNMfNE5HbgXWBthbcbaYxZWd329EhfKeULdh46wXsLtvHhknyOniwlLSmGUZmpXNqlGYEBNY529zq9IlcppTzg+KlSPsrazrsLtpG3v4jEmDDuvDCZm3q1Iio0yO7yfqShr5RSHlTmNHy7fg9j5uWyJPcAESGB3JTeijsvTKZVE/vb/TX0lVKqjqwuOMyYeVuZlr0LpzFc2sVq9+/ZujEi9gz51NBXSqk6tvvwScYv3MYHi/M5fKKEHq1iGJWZwuVdmxPk5XZ/DX2llPKSouJSpi7fwdh5ueTuO05CdCgjL0hmWO8kosO80+6voa+UUl7mdBq+31jIO3NzWbh1P+HBAT+2+7eObVSn29bQV0opG63deZgx83L5YtVOSp2Gizs1Y1RmCr1TmtRJu7+GvlJK+YDCIyf536I83l+Ux8GiEromRnF3ZipXdEsgONBz7f4a+kop5UNOFJfxyYodjJm3lZy9x2kWFcKIC5K5tXcSMeHBtX5/DX2llPJBTqfhh817GTM3l3lb9hEWFMDQni2588JkUuMjzvl9NfSVUsrHbdh9hLHzcvl0xU5KnE6u6JbAq7ecf05t/jpHrlJK+biOzaN4ZmgPHr20I+8vyqPU6azzi7s09JVSymbxkSE8dHF7r2zL924Vp5RSqs5o6CullB/R0FdKKT+ioa+UUn5EQ18ppfyIhr5SSvkRDX2llPIjGvpKKeVHfO42DCKyF8irxVvEAfs8VI4naV1nR+s6O1rX2WmIdbU2xsTXtJLPhX5tiUiWO/ef8Dat6+xoXWdH6zo7/lyXNu8opZQf0dBXSik/0hBD/y27CzgDrevsaF1nR+s6O35bV4Nr01dKKXVmDfFIXyml1BnUy9AXkctEZKOIbBGRJ6pYHiIik1zLF4tIso/UNVJE9orIStfjbi/VNVZECkVkzRmWi4i87Ko7W0TSfKSuASJyuMLn9aSX6molIt+LyDoRWSsiD1Sxjtc/Mzfr8vpnJiKhIrJERFa56vprFet4/TvpZl22fCdd2w4QkRUiMq2KZXX3eRlj6tUDCABygFQgGFgFdK60zn3AG66fhwGTfKSukcCrNnxm/YE0YM0Zll8BfAUIkAEs9pG6BgDTbPi8EoA018+RwKYq/lt6/TNzsy6vf2auzyDC9XMQsBjIqLSOHd9Jd+qy5Tvp2vbDwIdV/feqy8+rPh7p9wa2GGO2GmOKgYnANZXWuQZ4z/XzFGCw1PUcZO7VZQtjzBzgQDWrXAOMN5ZFQIyIJPhAXbYwxuwyxix3/XwUWA8kVlrN65+Zm3V5neszOOb6Ncj1qNxZ6PXvpJt12UJEWgJXAu+cYZU6+7zqY+gnAtsr/F7Az//H/3EdY0wpcBiI9YG6AG5wNQdMEZFWdVyTu9yt3Q59XafnX4lIF29v3HVafT7WUWJFtn5m1dQFNnxmrqaKlUAhMNMYc8bPy4vfSXfqAnu+ky8CjwHOMyyvs8+rPoZ+ffYFkGyM6Q7MpHxPrqq2HOvS8h7AK8Cn3ty4iEQAU4EHjTFHvLnt6tRQly2fmTGmzBhzHtAS6C0iXb2x3Zq4UZfXv5MichVQaIxZVtfbqkp9DP0dQMW9cUvXc1WuIyKBQDSw3+66jDH7jTGnXL++A/Ss45rc5c5n6nXGmCOnT8+NMdOBIBGJ88a2RSQIK1g/MMZ8XMUqtnxmNdVl52fm2uYh4HvgskqL7PhO1liXTd/JC4GrRWQbVjPwIBF5v9I6dfZ51cfQXwq0E5EUEQnG6uT4vNI6nwMjXD8PBWYZV4+InXVVavO9GqtN1hd8Dgx3jUjJAA4bY3bZXZSIND/djikivbH+f63zoHBtcwyw3hjz/BlW8/pn5k5ddnxmIhIvIjGun8OAi4ENlVbz+nfSnbrs+E4aY35vjGlpjEnGyolZxpjbK61WZ59XoCfexJuMMaUi8hvgG6wRM2ONMWtF5P+ALGPM51hfjP+JyBasjsJhPlLXb0XkaqDUVdfIuq4LQEQmYI3qiBORAuAprE4tjDFvANOxRqNsAYqAO32krqHAr0SkFDgBDPPCzhusI7E7gNWu9mCAPwBJFWqz4zNzpy47PrME4D0RCcDayUw2xkyz+zvpZl22fCer4q3PS6/IVUopP1Ifm3eUUkqdIw19pZTyIxr6SinlRzT0lVLKj2joK6WUH9HQV0opP6Khr5RSfkRDXyml/Mj/A1DohxWIP3UiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2aedbd25dc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "train_model((model, encinf, decinf), train_samples, batch_size=batch_size, epochs=epochs, \n",
    "            train_split=0.95, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'basic_seq2seq_20k_50_300d_1-1_LSTM'\n",
    "model_file = model_name + '.h5'\n",
    "# create the model\n",
    "model, encinf, decinf = define_models_lstm(src_vocab_size=vocab_size, latent_dim=300, embedding_matrix=embedding_matrix,\n",
    "                             encoder_depth=1, decoder_depth=1, trainable_embeddings=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 157731\n",
      "Test samples: 1594\n"
     ]
    }
   ],
   "source": [
    "train_samples, test_samples = create_samples(data, max_seq_length=50, test_split=0.01)\n",
    "print('Train samples:', len(train_samples))\n",
    "print('Test samples:', len(test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/sw/python-3.5.2/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1170/1170 [==============================] - 1771s 2s/step - loss: 1.4571 - categorical_accuracy: 0.1212 - val_loss: 1.4295 - val_categorical_accuracy: 0.1212\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.42950, saving model to basic_seq2seq_20k_200+50_300d_1-1_LSTM.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruc0029/.local/lib/python3.5/site-packages/keras/engine/topology.py:2379: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 300) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 300) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "1170/1170 [==============================] - 1767s 2s/step - loss: 1.4005 - categorical_accuracy: 0.1268 - val_loss: 1.4137 - val_categorical_accuracy: 0.1240\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.42950 to 1.41367, saving model to basic_seq2seq_20k_200+50_300d_1-1_LSTM.h5\n",
      "Epoch 3/5\n",
      "1170/1170 [==============================] - 1764s 2s/step - loss: 1.3632 - categorical_accuracy: 0.1310 - val_loss: 1.3928 - val_categorical_accuracy: 0.1260\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.41367 to 1.39282, saving model to basic_seq2seq_20k_200+50_300d_1-1_LSTM.h5\n",
      "Epoch 4/5\n",
      "1170/1170 [==============================] - 1769s 2s/step - loss: 1.3340 - categorical_accuracy: 0.1343 - val_loss: 1.3804 - val_categorical_accuracy: 0.1279\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.39282 to 1.38038, saving model to basic_seq2seq_20k_200+50_300d_1-1_LSTM.h5\n",
      "Epoch 5/5\n",
      "1170/1170 [==============================] - 1764s 2s/step - loss: 1.3086 - categorical_accuracy: 0.1369 - val_loss: 1.3734 - val_categorical_accuracy: 0.1300\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.38038 to 1.37336, saving model to basic_seq2seq_20k_200+50_300d_1-1_LSTM.h5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Line2D' object has no attribute 'setp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-45ab2a58c9e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m train_model(model, train_samples, batch_size=batch_size, epochs=epochs, \n\u001b[0;32m----> 4\u001b[0;31m             train_split=0.95, model_name=model_name)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-6861e8ef25b9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_samples, batch_size, epochs, shuffle, n_folds, train_split, model_name)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-6861e8ef25b9>\u001b[0m in \u001b[0;36m_run_model\u001b[0;34m(train, val, model_file)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# plot current losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtrain_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-a21aeab140d8>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(losses, fname)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgist_ncar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'{} loss'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{} val loss'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-a21aeab140d8>\u001b[0m in \u001b[0;36mplot_loss\u001b[0;34m(loss, val_loss, color, fname, legend)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mtrain_loss_plt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mval_loss_plt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Line2D' object has no attribute 'setp'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2aedbd25dc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "train_model((model, encinf, decinf), train_samples, batch_size=batch_size, epochs=epochs, \n",
    "            train_split=0.95, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(input_text, tokenizer):\n",
    "    return tokenizer.texts_to_sequences([preprocess(input_text)])[0]\n",
    "\n",
    "def decode_sequence(encinf, decinf, input_seq, vocab_size, max_output_len=50):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encinf.predict(input_seq)\n",
    "    print('Sequence encoded')\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))  # time, features\n",
    "    # Populate the first word with the eos index (.\n",
    "    target_seq[0, 0] = eos_index\n",
    "    \n",
    "    decoder_inputs = [target_seq] + states_value\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    i = 1 # number of sampled words\n",
    "    while not stop_condition:\n",
    "        output, h, c = decinf.predict(decoder_inputs)\n",
    "        sampled_word_index = np.argmax(output[0, -1, :])  # batch, time, features\n",
    "        sampled_word = index_word[sampled_word_index]\n",
    "\n",
    "        decoded_sentence += sampled_word + ' '\n",
    "        # Exit condition: either hit max length or find stop character.\n",
    "        if sampled_word == eos_token or i > max_output_len:\n",
    "            stop_condition = True     \n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_word_index\n",
    "        i += 1\n",
    "        \n",
    "        # Update states\n",
    "        decoder_inputs = [target_seq, h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "def beam_decoder_lstm(encinf, decinf, input_seq, k, vocab_size, max_output_len=50):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encinf.predict(input_seq)\n",
    "    print('Sequence encoded')\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))  # time, features\n",
    "    # Populate the first word with the eos index.\n",
    "    target_seq[0,0] = eos_index\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''    \n",
    "    decoded_sequences = []\n",
    "    \n",
    "    # Init Beam Array\n",
    "    beams = [(target_seq, states_value, 1.0)]\n",
    "    \n",
    "    output_len = 1 # number of sampled words\n",
    "    while not stop_condition:        \n",
    "        all_candidates = []\n",
    "        for i in range(len(beams)):  # for each beam, try to append the next predicted word\n",
    "            # Get the values of the beam\n",
    "            target_seq, states_value, score = beams[i]\n",
    "            \n",
    "            # predict the next word and create candidate list\n",
    "            output, h, c = decinf.predict([target_seq] + states_value)\n",
    "            candidate_score_list = output[0][0]\n",
    "            \n",
    "            for j in range(len(candidate_score_list)):  # for each possible word, compute the score               \n",
    "                # Add each candidate to the target sequence.\n",
    "                candidate_seq = np.insert(target_seq, [1], j, axis=1)\n",
    "                candidate_beam = [candidate_seq, [h, c],  score*-np.log(candidate_score_list[j])]\n",
    "                all_candidates.append(candidate_beam)\n",
    "\n",
    "        # order all candidates by score\n",
    "        ordered = sorted(all_candidates, key=lambda tup:tup[2], reverse=True)\n",
    "        # select k best\n",
    "        beams = ordered[:k]\n",
    "        \n",
    "        # if a beam has the index of the eos, \n",
    "        # 1. Add the beam to decoded_sequences, \n",
    "        # 2. Remove it from beams \n",
    "        # 3. Lower number of beams (k)\n",
    "        for bindex, beam in enumerate(beams):\n",
    "            if beam[0][0][-1] == eos_index:\n",
    "                decoded_sequences.append(beam)\n",
    "                del beams[bindex]\n",
    "                k -= 1\n",
    "                   \n",
    "        # Exit condition: either each beam got eos or hit max length\n",
    "        if len(beams) == 0 or output_len > max_output_len:\n",
    "            # Add the beams that did not have eos so far to the decoded_sequences\n",
    "            decoded_sequences += beams\n",
    "            stop_condition = True \n",
    "\n",
    "        output_len += 1\n",
    "        \n",
    "    decoded_sentences = [' '.join([index_word[int(wi)-1] \n",
    "                                   for wi in seq[0]]) \n",
    "                         for seq, state, score in decoded_sequences]\n",
    "\n",
    "    return decoded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_line = \"\"\"You find yourself in a dimly lit room. Before you you can spot a table. On the other side of the room\n",
    "a poster hangs askew on the wall. examine poster.\"\"\"\n",
    "# test_line = \"\"\"inventory\"\"\"\n",
    "input_seq = prepare_input(test_line, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence encoded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'you are in a small clearing in a well marked forest path that extends to the east and south behind the house is a path leading down a path leads northwest and a path leads southeast and a path leads southeast and a passage leads southeast a small passage leads southeast '"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model, encinf, decinf = define_models_lstm(src_vocab_size=vocab_size, latent_dim=300, embedding_matrix=embedding_matrix,\n",
    "#                              encoder_depth=1, decoder_depth=1, trainable_embeddings=False)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['categorical_accuracy'])\n",
    "\n",
    "# # load the 200-long model\n",
    "# model_name = 'basic_seq2seq_20k_200_300d_1-1_LSTM'\n",
    "# if os.path.isfile(model_name + '.h5'):\n",
    "#     model.load_weights(model_name + '.h5')\n",
    "#     encinf.load_weights(model_name + '-encinf.h5')\n",
    "#     decinf.load_weights(model_name + '-decinf.h5')\n",
    "decode_sequence(encinf, decinf, input_seq, vocab_size, max_output_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence encoded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['UNK chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly sirens sirens sirens sirens chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly sirens sirens sirens sirens chilly chilly chilly chilly chilly',\n",
       " 'UNK chilly never chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly sirens sirens sirens sirens chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly chilly sirens sirens sirens sirens chilly chilly chilly chilly chilly']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_decoder_lstm(encinf, decinf, input_seq, 2, vocab_size, max_output_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniele\\AppData\\Local\\conda\\conda\\envs\\ml\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "from pycontractions import Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = {\n",
    "    '^x (.+)$': 'examine \\g<1>',\n",
    "    '^m$': 'commands',\n",
    "    '^l$' : 'look',\n",
    "    '^nw$' : 'northwest',\n",
    "    '^sw$' : 'southwest',\n",
    "    '^ne$' : 'northeast',\n",
    "    '^se$' : 'southeast',\n",
    "    '^w$' : 'west',\n",
    "    '^e$' : 'east',\n",
    "    '^n$' : 'north',\n",
    "    '^s$' : 'south',\n",
    "    '^i$' : 'inventory',\n",
    "    '^z$' : 'wait',\n",
    "    '^g$' : 'again'            \n",
    "}\n",
    "\n",
    "def parse_transcript(infile, outfile, contractions=None):\n",
    "    # convenience var to parse different interpreters\n",
    "    sleepmask = False\n",
    "    \n",
    "    # open the file and start stripping all lines not starting with \"\"\"Floyd |\"\"\"\n",
    "    with open(infile, 'r', encoding='utf-8') as inf, open(outfile, 'w', encoding='utf-8') as outf:\n",
    "        content = inf.read()\n",
    "        \n",
    "        # skip everything up to the last load attempt (if none, just assume the game's already loaded)\n",
    "        loads = re.finditer(string=content, pattern=r'say(?:s)? \\(to Floyd\\), \"(?:load( sleepmask)?) (?:.+)\"', flags=re.IGNORECASE)\n",
    "        load = None\n",
    "        for load in loads:\n",
    "            pass            \n",
    "        if load:\n",
    "            if load.group(1):\n",
    "                sleepmask = True\n",
    "            content = content[load.end():]\n",
    "        \n",
    "        # remove version commands \n",
    "        content = re.sub(repl='', string=content, pattern=r'say(?:s)? \\(to Floyd\\), \"version\".*?Floyd \\| >\\n', flags=re.IGNORECASE | re.DOTALL)\n",
    "        \n",
    "        # replace external commands with inline ones (unless we're using sleepmask, which does it for us)\n",
    "        if not sleepmask:\n",
    "            content = re.sub(repl='Floyd | > \\g<1>\\n', string=content, pattern=r'(?:.+) say(?:s)? \\(to Floyd\\), \"(.+)\"', flags=re.IGNORECASE)\n",
    "        content = content.split('\\n')\n",
    "        \n",
    "        # expand contractions\n",
    "        if contractions:\n",
    "            content = contractions.expand_texts(content, precise=True)\n",
    "        \n",
    "        ##############################################################\n",
    "        ### From here on, we consider everything part of the game. ###\n",
    "        ##############################################################\n",
    "        print('Parsing gameplay...')\n",
    "        \n",
    "        scene = []\n",
    "        about = False\n",
    "        for line in content:\n",
    "            # Strip away about commands\n",
    "            if about:\n",
    "                # Either match the explicit \"Q\" command, or look for the first empty command prompt\n",
    "                if re.match(string=line, pattern=r'^Floyd \\| >(?: q)?$', flags=re.IGNORECASE):\n",
    "                    print('Line [{}], about=False'.format(line))\n",
    "                    about = False\n",
    "                continue\n",
    "            else:\n",
    "                if re.match(string=line, pattern=r'^Floyd \\| > (about|help)$', flags=re.IGNORECASE):\n",
    "                    print('Line [{}], about=True'.format(line))\n",
    "                    about = True\n",
    "                    continue\n",
    "                    \n",
    "            # Just strip blank prompts and \"press <key> to continue\" lines\n",
    "            if re.match(string=line, pattern=r'^Floyd \\| >$'):\n",
    "                continue\n",
    "            if re.match(string=line, pattern=r'press (?:.+) to continue', flags=re.IGNORECASE):\n",
    "                continue\n",
    "                    \n",
    "            # Scene descriptions\n",
    "            match = re.match(string=line, pattern=r'^Floyd \\| ([^>#\\n]+)', flags=re.IGNORECASE)\n",
    "            if match:\n",
    "                scene.append(match.group(1).strip().lower())\n",
    "            \n",
    "            # user's commands are appended to the current scene\n",
    "            match = re.match(string=line, pattern=r'^Floyd \\| > (.+)', flags=re.IGNORECASE)        \n",
    "            if match:\n",
    "                command = match.group(1).strip().lower()\n",
    "                # replace shortcuts\n",
    "                for pattern,repl in commands.items():\n",
    "                    command = re.sub(string=command, pattern=pattern, repl=repl)\n",
    "                newline = '{}\\n{}\\n'.format(' '.join(scene).replace('  ', ' '), '> ' + command)\n",
    "                outf.write(newline)\n",
    "                \n",
    "                scene = []\n",
    "                \n",
    "        # Append the very last scene\n",
    "        if len(scene) > 0:\n",
    "            outf.write(' '.join(scene).replace('  ', ' '))\n",
    "            \n",
    "        print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infile = 'raw_weishaupt.txt'\n",
    "# outfile = 'parsed-weishaupt.txt'\n",
    "cont = Contractions(w2v_path=os.path.join(DATA_PATH, 'GoogleNews-vectors-negative300.bin'))\n",
    "cont.load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing file: [data/transcripts\\raw-12heads.txt]\n",
      "Parsing gameplay...\n",
      "Done.\n",
      "Parsing file: [data/transcripts\\raw-1893.txt]\n",
      "Parsing gameplay...\n",
      "Done.\n",
      "Parsing file: [data/transcripts\\raw-20160221-thesueno-utf8.txt]\n",
      "Parsing gameplay...\n"
     ]
    }
   ],
   "source": [
    "transcripts = glob('data/transcripts/*.txt')\n",
    "for transcript in transcripts:\n",
    "    print('Parsing file: [{}]'.format(transcript))\n",
    "    parsed = 'data/parsed/parsed-{}'.format('-'.join(transcript.split('-')[1:]))\n",
    "    parse_transcript(transcript, parsed, cont)\n",
    "    \n",
    "#     # move parsed files\n",
    "#     os.rename(transcript, os.path.join('data/done', os.path.basename(transcript)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus building\n",
    "Here we build a single corpus of `<scene_before, command, scene_after>` triplets to be used by the model.\n",
    "We save the model in h5py format for ease-of-use and perfomance reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now build a single corpus of triplets\n",
    "def preprocess(text):\n",
    "    return re.sub(repl='', string=text, pattern='[{}\\n\\t]'.format(''.join(punctuation)))\n",
    "\n",
    "def build_vocabulary(infile, w2v):\n",
    "    idx2word = set() # only count unique words\n",
    "    \n",
    "    with open(infile, 'r', encoding='utf-8') as f:            \n",
    "        for line in f:\n",
    "            line = preprocess(line)\n",
    "            for word in line.split(' '):\n",
    "                if len(word) > 0:\n",
    "                    idx2word.add(word)\n",
    "            \n",
    "    idx2word = list(idx2word)\n",
    "    idx2word.insert(0, '<PAD>')\n",
    "    idx2word.insert(1, '<UNK>')\n",
    "\n",
    "    vocab_size, vocab_dim = len(idx2word), w2v.vector_size\n",
    "    word2idx = {w:i for i,w in enumerate(idx2word)}\n",
    "    word2embeddings = {w:w2v[w] if w in w2v else np.zeros(vocab_dim) for w in idx2word}\n",
    "    \n",
    "    \n",
    "    return idx2word, word2idx, word2embeddings, (vocab_size, vocab_dim)\n",
    "\n",
    "# this assumes no newlines characters\n",
    "def sentence_to_embeddings(sentence, embeddings):\n",
    "    return [embeddings[word] for word in sentence.split(' ') if len(word) > 0]\n",
    "\n",
    "# prepare the data to fit the vector representation. Returns a generator \n",
    "def prepare_data(w2v):\n",
    "    files = glob('data/parsed/*.txt')\n",
    "    with open(infile, 'r', encoding='utf-8') as f:\n",
    "        data = []\n",
    "        for line in f:\n",
    "            data.append(np.array(sentence_to_embeddings(preprocess(line), w2v)))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml (3.6)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
